

================================================================
== Vivado HLS Report for 'convolution_filter'
================================================================
* Date:           Tue Sep 19 11:05:57 2017

* Version:        2016.2 (Build 1577090 on Thu Jun 02 16:59:10 MDT 2016)
* Project:        Configurable_Convolution_Filter
* Solution:       solution1
* Product family: zynq
* Target device:  xc7z020clg484-1


================================================================
== Performance Estimates
================================================================
+ Timing (ns): 
    * Summary: 
    +--------+-------+----------+------------+
    |  Clock | Target| Estimated| Uncertainty|
    +--------+-------+----------+------------+
    |ap_clk  |  41.67|     22.64|        5.21|
    +--------+-------+----------+------------+

+ Latency (clock cycles): 
    * Summary: 
    +--------+--------+--------+--------+---------+
    |     Latency     |     Interval    | Pipeline|
    |   min  |   max  |   min  |   max  |   Type  |
    +--------+--------+--------+--------+---------+
    |  310598|  310598|  310599|  310599|   none  |
    +--------+--------+--------+--------+---------+

    + Detail: 
        * Instance: 
        N/A

        * Loop: 
        +---------------------+--------+--------+----------+-----------+-----------+--------+----------+
        |                     |     Latency     | Iteration|  Initiation Interval  |  Trip  |          |
        |      Loop Name      |   min  |   max  |  Latency |  achieved |   target  |  Count | Pipelined|
        +---------------------+--------+--------+----------+-----------+-----------+--------+----------+
        |- Loop_row_Loop_col  |  310596|  310596|        29|          1|          1|  310569|    yes   |
        +---------------------+--------+--------+----------+-----------+-----------+--------+----------+

============================================================
+ Verbose Summary: Synthesis Manager
============================================================
InlineROM: 1
ExposeGlobal: 0
============================================================
+ Verbose Summary: CDFG Model
============================================================
IsTopModel: 1
ResetActiveHigh: 1
IsCombinational: 0
IsDatapathOnly: 0
HasWiredReturn: 1
HasMFsm: 0
HasVarLatency: 1
IsPipeline: 0
IsRtlPipelined: 0
IsInstanceOverlapped: 0
IsDontTouch: 0
HasImplIP: 0
IsGatedGlobalClock: 0

+ Individual pipeline summary: 
  * Pipeline-0: initiation interval (II) = 1, depth = 29


============================================================
+ Verbose Summary: Schedule
============================================================
* Number of FSM states: 31
* Pipeline: 1
  Pipeline-0: II = 1, D = 29, States = { 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 }
* Dataflow Pipeline: 0

* FSM state transitions: 
1 --> 
	2  / true
2 --> 
	3  / true
3 --> 
	31  / (exitcond_flatten)
	4  / (!exitcond_flatten)
4 --> 
	5  / true
5 --> 
	6  / true
6 --> 
	7  / true
7 --> 
	8  / true
8 --> 
	9  / true
9 --> 
	10  / true
10 --> 
	11  / true
11 --> 
	12  / true
12 --> 
	13  / true
13 --> 
	14  / true
14 --> 
	15  / true
15 --> 
	16  / true
16 --> 
	17  / true
17 --> 
	18  / true
18 --> 
	19  / true
19 --> 
	20  / true
20 --> 
	21  / true
21 --> 
	22  / true
22 --> 
	23  / true
23 --> 
	24  / true
24 --> 
	25  / true
25 --> 
	26  / true
26 --> 
	27  / true
27 --> 
	28  / true
28 --> 
	29  / true
29 --> 
	30  / true
30 --> 
	2  / true
31 --> 
* FSM state operations: 

 <State 1>: 1.57ns
ST_1: convolution_filter_ap_int_ap_2 [1/1] 0.00ns
.preheader51.preheader:0  %convolution_filter_ap_int_ap_2 = alloca i32

ST_1: convolution_filter_ap_int_ap_1 [1/1] 0.00ns
.preheader51.preheader:1  %convolution_filter_ap_int_ap_1 = alloca i32

ST_1: in_temp_V_1 [1/1] 0.00ns
.preheader51.preheader:2  %in_temp_V_1 = alloca i8

ST_1: window_V_5_6_loc_1 [1/1] 0.00ns
.preheader51.preheader:3  %window_V_5_6_loc_1 = alloca i8

ST_1: window_V_4_6_loc_1 [1/1] 0.00ns
.preheader51.preheader:4  %window_V_4_6_loc_1 = alloca i8

ST_1: window_V_3_6_loc_1 [1/1] 0.00ns
.preheader51.preheader:5  %window_V_3_6_loc_1 = alloca i8

ST_1: window_V_2_6_loc_1 [1/1] 0.00ns
.preheader51.preheader:6  %window_V_2_6_loc_1 = alloca i8

ST_1: window_V_1_6_loc_1 [1/1] 0.00ns
.preheader51.preheader:7  %window_V_1_6_loc_1 = alloca i8

ST_1: window_V_0_6_loc_1 [1/1] 0.00ns
.preheader51.preheader:8  %window_V_0_6_loc_1 = alloca i8

ST_1: stg_41 [1/1] 0.00ns
.preheader51.preheader:9  call void (...)* @_ssdm_op_SpecBitsMap([51 x i8]* %kernel_config_V), !map !7

ST_1: stg_42 [1/1] 0.00ns
.preheader51.preheader:10  call void (...)* @_ssdm_op_SpecBitsMap(i8* %in_img_V), !map !13

ST_1: stg_43 [1/1] 0.00ns
.preheader51.preheader:11  call void (...)* @_ssdm_op_SpecBitsMap(i8* %out_img_V), !map !19

ST_1: stg_44 [1/1] 0.00ns
.preheader51.preheader:12  call void (...)* @_ssdm_op_SpecTopModule([19 x i8]* @convolution_filter_str) nounwind

ST_1: empty [1/1] 0.00ns
.preheader51.preheader:13  %empty = call i32 (...)* @_ssdm_op_SpecMemCore([51 x i8]* %kernel_config_V, [1 x i8]* @p_str, [7 x i8]* @RAM_1P_str, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_1: stg_46 [1/1] 0.00ns
.preheader51.preheader:14  call void (...)* @_ssdm_op_SpecInterface([51 x i8]* %kernel_config_V, [10 x i8]* @p_str6, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str) nounwind

ST_1: stg_47 [1/1] 0.00ns
.preheader51.preheader:15  call void (...)* @_ssdm_op_SpecInterface(i8* %out_img_V, [5 x i8]* @p_str7, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str)

ST_1: stg_48 [1/1] 0.00ns
.preheader51.preheader:16  call void (...)* @_ssdm_op_SpecInterface(i8* %in_img_V, [5 x i8]* @p_str7, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str)

ST_1: kernel_config_V_addr [1/1] 0.00ns
.preheader51.preheader:17  %kernel_config_V_addr = getelementptr [51 x i8]* %kernel_config_V, i64 0, i64 49

ST_1: kernel_config_V_addr_1 [1/1] 0.00ns
.preheader51.preheader:18  %kernel_config_V_addr_1 = getelementptr [51 x i8]* %kernel_config_V, i64 0, i64 50

ST_1: window_V_0_6_load [1/1] 0.00ns
.preheader51.preheader:19  %window_V_0_6_load = load i8* @window_V_0_6, align 1

ST_1: window_V_1_6_load [1/1] 0.00ns
.preheader51.preheader:20  %window_V_1_6_load = load i8* @window_V_1_6, align 1

ST_1: window_V_2_6_load [1/1] 0.00ns
.preheader51.preheader:21  %window_V_2_6_load = load i8* @window_V_2_6, align 1

ST_1: window_V_3_6_load [1/1] 0.00ns
.preheader51.preheader:22  %window_V_3_6_load = load i8* @window_V_3_6, align 1

ST_1: window_V_4_6_load [1/1] 0.00ns
.preheader51.preheader:23  %window_V_4_6_load = load i8* @window_V_4_6, align 1

ST_1: window_V_5_6_load [1/1] 0.00ns
.preheader51.preheader:24  %window_V_5_6_load = load i8* @window_V_5_6, align 1

ST_1: window_V_6_6_load [1/1] 0.00ns
.preheader51.preheader:25  %window_V_6_6_load = load i8* @window_V_6_6, align 1

ST_1: stg_58 [1/1] 1.57ns
.preheader51.preheader:26  store i8 %window_V_0_6_load, i8* %window_V_0_6_loc_1

ST_1: stg_59 [1/1] 1.57ns
.preheader51.preheader:27  store i8 %window_V_1_6_load, i8* %window_V_1_6_loc_1

ST_1: stg_60 [1/1] 1.57ns
.preheader51.preheader:28  store i8 %window_V_2_6_load, i8* %window_V_2_6_loc_1

ST_1: stg_61 [1/1] 1.57ns
.preheader51.preheader:29  store i8 %window_V_3_6_load, i8* %window_V_3_6_loc_1

ST_1: stg_62 [1/1] 1.57ns
.preheader51.preheader:30  store i8 %window_V_4_6_load, i8* %window_V_4_6_loc_1

ST_1: stg_63 [1/1] 1.57ns
.preheader51.preheader:31  store i8 %window_V_5_6_load, i8* %window_V_5_6_loc_1

ST_1: stg_64 [1/1] 1.57ns
.preheader51.preheader:32  store i8 %window_V_6_6_load, i8* %in_temp_V_1

ST_1: stg_65 [1/1] 1.57ns
.preheader51.preheader:33  store i32 0, i32* %convolution_filter_ap_int_ap_1

ST_1: stg_66 [1/1] 1.57ns
.preheader51.preheader:34  store i32 0, i32* %convolution_filter_ap_int_ap_2

ST_1: stg_67 [1/1] 1.57ns
.preheader51.preheader:35  br label %0


 <State 2>: 8.52ns
ST_2: indvar_flatten [1/1] 0.00ns
:0  %indvar_flatten = phi i19 [ 0, %.preheader51.preheader ], [ %indvar_flatten_next, %._crit_edge66 ]

ST_2: convolution_mulfilter_ap_int_ap [1/1] 0.00ns
:1  %convolution_mulfilter_ap_int_ap = phi i19 [ 0, %.preheader51.preheader ], [ %convolution_filter_ap_int_ap_7, %._crit_edge66 ]

ST_2: row [1/1] 0.00ns
:2  %row = phi i9 [ 0, %.preheader51.preheader ], [ %row_mid2, %._crit_edge66 ]

ST_2: convolution_filter_ap_int_ap_3 [1/1] 0.00ns
:3  %convolution_filter_ap_int_ap_3 = phi i19 [ 0, %.preheader51.preheader ], [ %tmp_32, %._crit_edge66 ]

ST_2: col [1/1] 0.00ns
:4  %col = phi i10 [ 0, %.preheader51.preheader ], [ %col_1, %._crit_edge66 ]

ST_2: exitcond_flatten [1/1] 2.33ns
:12  %exitcond_flatten = icmp eq i19 %indvar_flatten, -213719

ST_2: indvar_flatten_next [1/1] 2.08ns
:13  %indvar_flatten_next = add i19 %indvar_flatten, 1

ST_2: stg_75 [1/1] 0.00ns
:14  br i1 %exitcond_flatten, label %7, label %.reset

ST_2: stg_76 [1/1] 0.00ns
.reset:0  call void (...)* @_ssdm_op_SpecLoopName([18 x i8]* @Loop_row_Loop_col_str)

ST_2: empty_53 [1/1] 0.00ns
.reset:1  %empty_53 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 310569, i64 310569, i64 310569)

ST_2: tmp_2 [1/1] 2.08ns
.reset:2  %tmp_2 = add i19 %convolution_mulfilter_ap_int_ap, 643

ST_2: exitcond [1/1] 2.07ns
.reset:3  %exitcond = icmp eq i10 %col, -381

ST_2: convolution_filter_ap_int_ap_6 [1/1] 1.37ns
.reset:4  %convolution_filter_ap_int_ap_6 = select i1 %exitcond, i19 %tmp_2, i19 %convolution_filter_ap_int_ap_3

ST_2: col_mid2 [1/1] 1.37ns
.reset:5  %col_mid2 = select i1 %exitcond, i10 0, i10 %col

ST_2: row_s [1/1] 1.84ns
.reset:6  %row_s = add i9 %row, 1

ST_2: tmp_mid1 [1/1] 2.03ns
.reset:7  %tmp_mid1 = icmp ult i9 %row_s, -32

ST_2: tmp [1/1] 2.03ns
.reset:8  %tmp = icmp ult i9 %row, -32

ST_2: tmp_mid2 [1/1] 1.37ns
.reset:9  %tmp_mid2 = select i1 %exitcond, i1 %tmp_mid1, i1 %tmp

ST_2: tmp_2_mid1 [1/1] 2.03ns
.reset:10  %tmp_2_mid1 = icmp ugt i9 %row_s, 2

ST_2: tmp_9 [1/1] 2.03ns
.reset:11  %tmp_9 = icmp ugt i9 %row, 2

ST_2: tmp_2_mid2 [1/1] 1.37ns
.reset:12  %tmp_2_mid2 = select i1 %exitcond, i1 %tmp_2_mid1, i1 %tmp_9

ST_2: convolution_filter_ap_int_ap_7 [1/1] 1.37ns
.reset:13  %convolution_filter_ap_int_ap_7 = select i1 %exitcond, i19 %tmp_2, i19 %convolution_mulfilter_ap_int_ap

ST_2: row_mid2 [1/1] 1.37ns
.reset:14  %row_mid2 = select i1 %exitcond, i9 %row_s, i9 %row

ST_2: stg_91 [1/1] 0.00ns
.reset:15  call void (...)* @_ssdm_op_SpecLoopName([9 x i8]* @p_str10) nounwind

ST_2: tmp_1 [1/1] 0.00ns
.reset:16  %tmp_1 = call i32 (...)* @_ssdm_op_SpecRegionBegin([9 x i8]* @p_str10)

ST_2: stg_93 [1/1] 0.00ns
.reset:17  call void (...)* @_ssdm_op_SpecPipeline(i32 1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind

ST_2: tmp_4 [1/1] 2.33ns
.reset:18  %tmp_4 = icmp ult i19 %convolution_filter_ap_int_ap_6, 49

ST_2: stg_95 [1/1] 0.00ns
.reset:19  br i1 %tmp_4, label %._crit_edge63, label %1

ST_2: tmp_6 [1/1] 2.33ns
:0  %tmp_6 = icmp eq i19 %convolution_filter_ap_int_ap_6, 49

ST_2: stg_97 [1/1] 0.00ns
:1  br i1 %tmp_6, label %2, label %3

ST_2: tmp_8 [1/1] 2.33ns
:0  %tmp_8 = icmp eq i19 %convolution_filter_ap_int_ap_6, 50

ST_2: stg_99 [1/1] 0.00ns
:1  br i1 %tmp_8, label %4, label %._crit_edge64

ST_2: kernel_config_V_load_2 [2/2] 2.39ns
:0  %kernel_config_V_load_2 = load i8* %kernel_config_V_addr_1, align 1

ST_2: stg_101 [1/1] 0.00ns
._crit_edge64:0  br label %5

ST_2: kernel_config_V_load_1 [2/2] 2.39ns
:0  %kernel_config_V_load_1 = load i8* %kernel_config_V_addr, align 1

ST_2: stg_103 [1/1] 0.00ns
:0  br label %.preheader45.preheader.0

ST_2: convolution_filter_ap_int_ap_4 [1/1] 0.00ns
._crit_edge63:0  %convolution_filter_ap_int_ap_4 = load i32* %convolution_filter_ap_int_ap_2

ST_2: convolution_filter_ap_int_ap_5 [1/1] 0.00ns
._crit_edge63:1  %convolution_filter_ap_int_ap_5 = load i32* %convolution_filter_ap_int_ap_1

ST_2: tmp_5 [1/1] 2.52ns
._crit_edge63:2  %tmp_5 = icmp sgt i32 %convolution_filter_ap_int_ap_4, 6

ST_2: tmp_7 [1/1] 2.44ns
._crit_edge63:3  %tmp_7 = add nsw i32 1, %convolution_filter_ap_int_ap_5

ST_2: sel_SEBB [1/1] 1.37ns
._crit_edge63:4  %sel_SEBB = select i1 %tmp_5, i32 %tmp_7, i32 %convolution_filter_ap_int_ap_5

ST_2: sel_SEBB1 [1/1] 1.37ns
._crit_edge63:5  %sel_SEBB1 = select i1 %tmp_5, i32 0, i32 %convolution_filter_ap_int_ap_4

ST_2: tmp_s [1/1] 0.00ns
._crit_edge63:6  %tmp_s = zext i19 %convolution_filter_ap_int_ap_6 to i64

ST_2: kernel_config_V_addr_2 [1/1] 0.00ns
._crit_edge63:7  %kernel_config_V_addr_2 = getelementptr [51 x i8]* %kernel_config_V, i64 0, i64 %tmp_s

ST_2: kernel_config_V_load [2/2] 2.39ns
._crit_edge63:8  %kernel_config_V_load = load i8* %kernel_config_V_addr_2, align 1

ST_2: tmp_64 [1/1] 0.00ns
._crit_edge63:9  %tmp_64 = trunc i32 %sel_SEBB to i3

ST_2: tmp_65 [1/1] 0.00ns
._crit_edge63:10  %tmp_65 = trunc i32 %sel_SEBB1 to i3

ST_2: stg_115 [1/1] 1.88ns
._crit_edge63:11  switch i3 %tmp_64, label %branch6 [
    i3 0, label %branch0
    i3 1, label %branch1
    i3 2, label %branch2
    i3 3, label %branch3
    i3 -4, label %branch4
    i3 -3, label %branch5
  ]

ST_2: stg_116 [1/1] 1.88ns
branch5:0  switch i3 %tmp_65, label %branch48 [
    i3 0, label %branch42
    i3 1, label %branch43
    i3 2, label %branch44
    i3 3, label %branch45
    i3 -4, label %branch46
    i3 -3, label %branch47
  ]

ST_2: stg_117 [1/1] 0.00ns
branch5129:0  br label %._crit_edge6376

ST_2: stg_118 [1/1] 1.88ns
branch4:0  switch i3 %tmp_65, label %branch41 [
    i3 0, label %branch35
    i3 1, label %branch36
    i3 2, label %branch37
    i3 3, label %branch38
    i3 -4, label %branch39
    i3 -3, label %branch40
  ]

ST_2: stg_119 [1/1] 0.00ns
branch4120:0  br label %._crit_edge6376

ST_2: stg_120 [1/1] 1.88ns
branch3:0  switch i3 %tmp_65, label %branch34 [
    i3 0, label %branch28
    i3 1, label %branch29
    i3 2, label %branch30
    i3 3, label %branch31
    i3 -4, label %branch32
    i3 -3, label %branch33
  ]

ST_2: stg_121 [1/1] 0.00ns
branch3111:0  br label %._crit_edge6376

ST_2: stg_122 [1/1] 1.88ns
branch2:0  switch i3 %tmp_65, label %branch27 [
    i3 0, label %branch21
    i3 1, label %branch22
    i3 2, label %branch23
    i3 3, label %branch24
    i3 -4, label %branch25
    i3 -3, label %branch26
  ]

ST_2: stg_123 [1/1] 0.00ns
branch2102:0  br label %._crit_edge6376

ST_2: stg_124 [1/1] 1.88ns
branch1:0  switch i3 %tmp_65, label %branch20 [
    i3 0, label %branch14
    i3 1, label %branch15
    i3 2, label %branch16
    i3 3, label %branch17
    i3 -4, label %branch18
    i3 -3, label %branch19
  ]

ST_2: stg_125 [1/1] 0.00ns
branch193:0  br label %._crit_edge6376

ST_2: stg_126 [1/1] 1.88ns
branch0:0  switch i3 %tmp_65, label %branch13 [
    i3 0, label %branch7
    i3 1, label %branch8
    i3 2, label %branch9
    i3 3, label %branch10
    i3 -4, label %branch11
    i3 -3, label %branch12
  ]

ST_2: stg_127 [1/1] 0.00ns
branch084:0  br label %._crit_edge6376

ST_2: stg_128 [1/1] 1.88ns
branch6:0  switch i3 %tmp_65, label %branch55 [
    i3 0, label %branch49
    i3 1, label %branch50
    i3 2, label %branch51
    i3 3, label %branch52
    i3 -4, label %branch53
    i3 -3, label %branch54
  ]

ST_2: stg_129 [1/1] 0.00ns
branch6138:0  br label %._crit_edge6376

ST_2: tmp_3 [1/1] 2.44ns
._crit_edge6376:0  %tmp_3 = add nsw i32 %sel_SEBB1, 1

ST_2: stg_131 [1/1] 1.57ns
._crit_edge6376:1  store i32 %sel_SEBB, i32* %convolution_filter_ap_int_ap_1

ST_2: stg_132 [1/1] 1.57ns
._crit_edge6376:2  store i32 %tmp_3, i32* %convolution_filter_ap_int_ap_2

ST_2: stg_133 [1/1] 0.00ns
._crit_edge6376:3  br label %.preheader45.preheader.0

ST_2: tmp_10 [1/1] 2.07ns
.preheader45.preheader.0:70  %tmp_10 = icmp ult i10 %col_mid2, -384

ST_2: stg_135 [1/1] 0.00ns
.preheader45.preheader.0:71  br i1 %tmp_10, label %.preheader.preheader, label %.loopexit

ST_2: tmp_11 [1/1] 0.00ns
.preheader.preheader:0  %tmp_11 = zext i10 %col_mid2 to i64

ST_2: line_buffer_V_0_addr [1/1] 0.00ns
.preheader.preheader:1  %line_buffer_V_0_addr = getelementptr [640 x i8]* @line_buffer_V_0, i64 0, i64 %tmp_11

ST_2: line_buffer_V_0_load [2/2] 2.71ns
.preheader.preheader:2  %line_buffer_V_0_load = load i8* %line_buffer_V_0_addr, align 1

ST_2: line_buffer_V_1_addr [1/1] 0.00ns
.preheader.preheader:4  %line_buffer_V_1_addr = getelementptr [640 x i8]* @line_buffer_V_1, i64 0, i64 %tmp_11

ST_2: line_buffer_V_1_load [2/2] 2.71ns
.preheader.preheader:5  %line_buffer_V_1_load = load i8* %line_buffer_V_1_addr, align 1

ST_2: line_buffer_V_2_addr [1/1] 0.00ns
.preheader.preheader:8  %line_buffer_V_2_addr = getelementptr [640 x i8]* @line_buffer_V_2, i64 0, i64 %tmp_11

ST_2: line_buffer_V_2_load [2/2] 2.71ns
.preheader.preheader:9  %line_buffer_V_2_load = load i8* %line_buffer_V_2_addr, align 1

ST_2: line_buffer_V_3_addr [1/1] 0.00ns
.preheader.preheader:12  %line_buffer_V_3_addr = getelementptr [640 x i8]* @line_buffer_V_3, i64 0, i64 %tmp_11

ST_2: line_buffer_V_3_load [2/2] 2.71ns
.preheader.preheader:13  %line_buffer_V_3_load = load i8* %line_buffer_V_3_addr, align 1

ST_2: line_buffer_V_4_addr [1/1] 0.00ns
.preheader.preheader:16  %line_buffer_V_4_addr = getelementptr [640 x i8]* @line_buffer_V_4, i64 0, i64 %tmp_11

ST_2: line_buffer_V_4_load [2/2] 2.71ns
.preheader.preheader:17  %line_buffer_V_4_load = load i8* %line_buffer_V_4_addr, align 1

ST_2: line_buffer_V_5_addr [1/1] 0.00ns
.preheader.preheader:20  %line_buffer_V_5_addr = getelementptr [640 x i8]* @line_buffer_V_5, i64 0, i64 %tmp_11

ST_2: line_buffer_V_5_load [2/2] 2.71ns
.preheader.preheader:21  %line_buffer_V_5_load = load i8* %line_buffer_V_5_addr, align 1

ST_2: or_cond [1/1] 1.37ns
.loopexit:0  %or_cond = and i1 %tmp_10, %tmp_mid2

ST_2: stg_150 [1/1] 0.00ns
.loopexit:1  br i1 %or_cond, label %6, label %.loopexit._crit_edge

ST_2: in_temp_V [1/1] 0.00ns
:0  %in_temp_V = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %in_img_V)

ST_2: stg_152 [1/1] 0.00ns
:1  store i8 %in_temp_V, i8* @window_V_6_6, align 2

ST_2: tmp_13 [1/1] 2.07ns
.loopexit._crit_edge:0  %tmp_13 = icmp ugt i10 %col_mid2, 2

ST_2: or_cond1 [1/1] 1.37ns
.loopexit._crit_edge:1  %or_cond1 = and i1 %tmp_2_mid2, %tmp_13

ST_2: stg_155 [1/1] 0.00ns
.loopexit._crit_edge:2  br i1 %or_cond1, label %pixel_weighted_average.exit, label %._crit_edge66

ST_2: tmp_32 [1/1] 2.08ns
._crit_edge66:0  %tmp_32 = add i19 %convolution_filter_ap_int_ap_6, 1

ST_2: empty_52 [1/1] 0.00ns
._crit_edge66:1  %empty_52 = call i32 (...)* @_ssdm_op_SpecRegionEnd([9 x i8]* @p_str10, i32 %tmp_1)

ST_2: col_1 [1/1] 1.84ns
._crit_edge66:2  %col_1 = add i10 %col_mid2, 1

ST_2: stg_159 [1/1] 0.00ns
._crit_edge66:3  br label %0


 <State 3>: 5.42ns
ST_3: in_temp_V_1_load [1/1] 0.00ns
:5  %in_temp_V_1_load = load i8* %in_temp_V_1

ST_3: window_V_5_6_loc_1_load [1/1] 0.00ns
:6  %window_V_5_6_loc_1_load = load i8* %window_V_5_6_loc_1

ST_3: window_V_4_6_loc_1_load [1/1] 0.00ns
:7  %window_V_4_6_loc_1_load = load i8* %window_V_4_6_loc_1

ST_3: window_V_3_6_loc_1_load [1/1] 0.00ns
:8  %window_V_3_6_loc_1_load = load i8* %window_V_3_6_loc_1

ST_3: window_V_2_6_loc_1_load [1/1] 0.00ns
:9  %window_V_2_6_loc_1_load = load i8* %window_V_2_6_loc_1

ST_3: window_V_1_6_loc_1_load [1/1] 0.00ns
:10  %window_V_1_6_loc_1_load = load i8* %window_V_1_6_loc_1

ST_3: window_V_0_6_loc_1_load [1/1] 0.00ns
:11  %window_V_0_6_loc_1_load = load i8* %window_V_0_6_loc_1

ST_3: kernel_config_V_load_2 [1/2] 2.39ns
:0  %kernel_config_V_load_2 = load i8* %kernel_config_V_addr_1, align 1

ST_3: stg_168 [1/1] 0.00ns
:1  store i8 %kernel_config_V_load_2, i8* @kernel_off_V, align 1

ST_3: stg_169 [1/1] 0.00ns
:2  br label %._crit_edge64

ST_3: kernel_config_V_load_1 [1/2] 2.39ns
:0  %kernel_config_V_load_1 = load i8* %kernel_config_V_addr, align 1

ST_3: stg_171 [1/1] 0.00ns
:1  store i8 %kernel_config_V_load_1, i8* @kernel_sum_V, align 1

ST_3: stg_172 [1/1] 0.00ns
:2  br label %5

ST_3: kernel_config_V_load [1/2] 2.39ns
._crit_edge63:8  %kernel_config_V_load = load i8* %kernel_config_V_addr_2, align 1

ST_3: stg_174 [1/1] 0.00ns
branch47:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_5, align 1

ST_3: stg_175 [1/1] 0.00ns
branch47:1  br label %branch5129

ST_3: stg_176 [1/1] 0.00ns
branch46:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_4, align 1

ST_3: stg_177 [1/1] 0.00ns
branch46:1  br label %branch5129

ST_3: stg_178 [1/1] 0.00ns
branch45:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_3, align 1

ST_3: stg_179 [1/1] 0.00ns
branch45:1  br label %branch5129

ST_3: stg_180 [1/1] 0.00ns
branch44:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_2, align 1

ST_3: stg_181 [1/1] 0.00ns
branch44:1  br label %branch5129

ST_3: stg_182 [1/1] 0.00ns
branch43:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_1, align 1

ST_3: stg_183 [1/1] 0.00ns
branch43:1  br label %branch5129

ST_3: stg_184 [1/1] 0.00ns
branch42:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_0, align 1

ST_3: stg_185 [1/1] 0.00ns
branch42:1  br label %branch5129

ST_3: stg_186 [1/1] 0.00ns
branch48:0  store i8 %kernel_config_V_load, i8* @kernel_V_5_6, align 1

ST_3: stg_187 [1/1] 0.00ns
branch48:1  br label %branch5129

ST_3: stg_188 [1/1] 0.00ns
branch40:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_5, align 1

ST_3: stg_189 [1/1] 0.00ns
branch40:1  br label %branch4120

ST_3: stg_190 [1/1] 0.00ns
branch39:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_4, align 1

ST_3: stg_191 [1/1] 0.00ns
branch39:1  br label %branch4120

ST_3: stg_192 [1/1] 0.00ns
branch38:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_3, align 1

ST_3: stg_193 [1/1] 0.00ns
branch38:1  br label %branch4120

ST_3: stg_194 [1/1] 0.00ns
branch37:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_2, align 1

ST_3: stg_195 [1/1] 0.00ns
branch37:1  br label %branch4120

ST_3: stg_196 [1/1] 0.00ns
branch36:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_1, align 1

ST_3: stg_197 [1/1] 0.00ns
branch36:1  br label %branch4120

ST_3: stg_198 [1/1] 0.00ns
branch35:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_0, align 1

ST_3: stg_199 [1/1] 0.00ns
branch35:1  br label %branch4120

ST_3: stg_200 [1/1] 0.00ns
branch41:0  store i8 %kernel_config_V_load, i8* @kernel_V_4_6, align 1

ST_3: stg_201 [1/1] 0.00ns
branch41:1  br label %branch4120

ST_3: stg_202 [1/1] 0.00ns
branch33:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_5, align 1

ST_3: stg_203 [1/1] 0.00ns
branch33:1  br label %branch3111

ST_3: stg_204 [1/1] 0.00ns
branch32:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_4, align 1

ST_3: stg_205 [1/1] 0.00ns
branch32:1  br label %branch3111

ST_3: stg_206 [1/1] 0.00ns
branch31:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_3, align 1

ST_3: stg_207 [1/1] 0.00ns
branch31:1  br label %branch3111

ST_3: stg_208 [1/1] 0.00ns
branch30:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_2, align 1

ST_3: stg_209 [1/1] 0.00ns
branch30:1  br label %branch3111

ST_3: stg_210 [1/1] 0.00ns
branch29:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_1, align 1

ST_3: stg_211 [1/1] 0.00ns
branch29:1  br label %branch3111

ST_3: stg_212 [1/1] 0.00ns
branch28:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_0, align 1

ST_3: stg_213 [1/1] 0.00ns
branch28:1  br label %branch3111

ST_3: stg_214 [1/1] 0.00ns
branch34:0  store i8 %kernel_config_V_load, i8* @kernel_V_3_6, align 1

ST_3: stg_215 [1/1] 0.00ns
branch34:1  br label %branch3111

ST_3: stg_216 [1/1] 0.00ns
branch26:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_5, align 1

ST_3: stg_217 [1/1] 0.00ns
branch26:1  br label %branch2102

ST_3: stg_218 [1/1] 0.00ns
branch25:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_4, align 1

ST_3: stg_219 [1/1] 0.00ns
branch25:1  br label %branch2102

ST_3: stg_220 [1/1] 0.00ns
branch24:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_3, align 1

ST_3: stg_221 [1/1] 0.00ns
branch24:1  br label %branch2102

ST_3: stg_222 [1/1] 0.00ns
branch23:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_2, align 1

ST_3: stg_223 [1/1] 0.00ns
branch23:1  br label %branch2102

ST_3: stg_224 [1/1] 0.00ns
branch22:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_1, align 1

ST_3: stg_225 [1/1] 0.00ns
branch22:1  br label %branch2102

ST_3: stg_226 [1/1] 0.00ns
branch21:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_0, align 1

ST_3: stg_227 [1/1] 0.00ns
branch21:1  br label %branch2102

ST_3: stg_228 [1/1] 0.00ns
branch27:0  store i8 %kernel_config_V_load, i8* @kernel_V_2_6, align 1

ST_3: stg_229 [1/1] 0.00ns
branch27:1  br label %branch2102

ST_3: stg_230 [1/1] 0.00ns
branch19:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_5, align 1

ST_3: stg_231 [1/1] 0.00ns
branch19:1  br label %branch193

ST_3: stg_232 [1/1] 0.00ns
branch18:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_4, align 1

ST_3: stg_233 [1/1] 0.00ns
branch18:1  br label %branch193

ST_3: stg_234 [1/1] 0.00ns
branch17:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_3, align 1

ST_3: stg_235 [1/1] 0.00ns
branch17:1  br label %branch193

ST_3: stg_236 [1/1] 0.00ns
branch16:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_2, align 1

ST_3: stg_237 [1/1] 0.00ns
branch16:1  br label %branch193

ST_3: stg_238 [1/1] 0.00ns
branch15:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_1, align 1

ST_3: stg_239 [1/1] 0.00ns
branch15:1  br label %branch193

ST_3: stg_240 [1/1] 0.00ns
branch14:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_0, align 1

ST_3: stg_241 [1/1] 0.00ns
branch14:1  br label %branch193

ST_3: stg_242 [1/1] 0.00ns
branch20:0  store i8 %kernel_config_V_load, i8* @kernel_V_1_6, align 1

ST_3: stg_243 [1/1] 0.00ns
branch20:1  br label %branch193

ST_3: stg_244 [1/1] 0.00ns
branch12:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_5, align 1

ST_3: stg_245 [1/1] 0.00ns
branch12:1  br label %branch084

ST_3: stg_246 [1/1] 0.00ns
branch11:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_4, align 1

ST_3: stg_247 [1/1] 0.00ns
branch11:1  br label %branch084

ST_3: stg_248 [1/1] 0.00ns
branch10:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_3, align 1

ST_3: stg_249 [1/1] 0.00ns
branch10:1  br label %branch084

ST_3: stg_250 [1/1] 0.00ns
branch9:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_2, align 1

ST_3: stg_251 [1/1] 0.00ns
branch9:1  br label %branch084

ST_3: stg_252 [1/1] 0.00ns
branch8:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_1, align 1

ST_3: stg_253 [1/1] 0.00ns
branch8:1  br label %branch084

ST_3: stg_254 [1/1] 0.00ns
branch7:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_0, align 1

ST_3: stg_255 [1/1] 0.00ns
branch7:1  br label %branch084

ST_3: stg_256 [1/1] 0.00ns
branch13:0  store i8 %kernel_config_V_load, i8* @kernel_V_0_6, align 1

ST_3: stg_257 [1/1] 0.00ns
branch13:1  br label %branch084

ST_3: stg_258 [1/1] 0.00ns
branch54:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_5, align 1

ST_3: stg_259 [1/1] 0.00ns
branch54:1  br label %branch6138

ST_3: stg_260 [1/1] 0.00ns
branch53:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_4, align 1

ST_3: stg_261 [1/1] 0.00ns
branch53:1  br label %branch6138

ST_3: stg_262 [1/1] 0.00ns
branch52:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_3, align 1

ST_3: stg_263 [1/1] 0.00ns
branch52:1  br label %branch6138

ST_3: stg_264 [1/1] 0.00ns
branch51:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_2, align 1

ST_3: stg_265 [1/1] 0.00ns
branch51:1  br label %branch6138

ST_3: stg_266 [1/1] 0.00ns
branch50:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_1, align 1

ST_3: stg_267 [1/1] 0.00ns
branch50:1  br label %branch6138

ST_3: stg_268 [1/1] 0.00ns
branch49:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_0, align 1

ST_3: stg_269 [1/1] 0.00ns
branch49:1  br label %branch6138

ST_3: stg_270 [1/1] 0.00ns
branch55:0  store i8 %kernel_config_V_load, i8* @kernel_V_6_6, align 1

ST_3: stg_271 [1/1] 0.00ns
branch55:1  br label %branch6138

ST_3: line_buffer_V_0_load [1/2] 2.71ns
.preheader.preheader:2  %line_buffer_V_0_load = load i8* %line_buffer_V_0_addr, align 1

ST_3: stg_273 [1/1] 0.00ns
.preheader.preheader:3  store i8 %line_buffer_V_0_load, i8* @window_V_0_6, align 2

ST_3: line_buffer_V_1_load [1/2] 2.71ns
.preheader.preheader:5  %line_buffer_V_1_load = load i8* %line_buffer_V_1_addr, align 1

ST_3: stg_275 [1/1] 2.71ns
.preheader.preheader:6  store i8 %line_buffer_V_1_load, i8* %line_buffer_V_0_addr, align 1

ST_3: stg_276 [1/1] 0.00ns
.preheader.preheader:7  store i8 %line_buffer_V_1_load, i8* @window_V_1_6, align 1

ST_3: line_buffer_V_2_load [1/2] 2.71ns
.preheader.preheader:9  %line_buffer_V_2_load = load i8* %line_buffer_V_2_addr, align 1

ST_3: stg_278 [1/1] 2.71ns
.preheader.preheader:10  store i8 %line_buffer_V_2_load, i8* %line_buffer_V_1_addr, align 1

ST_3: stg_279 [1/1] 0.00ns
.preheader.preheader:11  store i8 %line_buffer_V_2_load, i8* @window_V_2_6, align 2

ST_3: line_buffer_V_3_load [1/2] 2.71ns
.preheader.preheader:13  %line_buffer_V_3_load = load i8* %line_buffer_V_3_addr, align 1

ST_3: stg_281 [1/1] 2.71ns
.preheader.preheader:14  store i8 %line_buffer_V_3_load, i8* %line_buffer_V_2_addr, align 1

ST_3: stg_282 [1/1] 0.00ns
.preheader.preheader:15  store i8 %line_buffer_V_3_load, i8* @window_V_3_6, align 1

ST_3: line_buffer_V_4_load [1/2] 2.71ns
.preheader.preheader:17  %line_buffer_V_4_load = load i8* %line_buffer_V_4_addr, align 1

ST_3: stg_284 [1/1] 2.71ns
.preheader.preheader:18  store i8 %line_buffer_V_4_load, i8* %line_buffer_V_3_addr, align 1

ST_3: stg_285 [1/1] 0.00ns
.preheader.preheader:19  store i8 %line_buffer_V_4_load, i8* @window_V_4_6, align 2

ST_3: line_buffer_V_5_load [1/2] 2.71ns
.preheader.preheader:21  %line_buffer_V_5_load = load i8* %line_buffer_V_5_addr, align 1

ST_3: stg_287 [1/1] 2.71ns
.preheader.preheader:22  store i8 %line_buffer_V_5_load, i8* %line_buffer_V_4_addr, align 1

ST_3: stg_288 [1/1] 0.00ns
.preheader.preheader:23  store i8 %line_buffer_V_5_load, i8* @window_V_5_6, align 1

ST_3: stg_289 [1/1] 1.57ns
.preheader.preheader:24  store i8 %line_buffer_V_0_load, i8* %window_V_0_6_loc_1

ST_3: stg_290 [1/1] 1.57ns
.preheader.preheader:25  store i8 %line_buffer_V_1_load, i8* %window_V_1_6_loc_1

ST_3: stg_291 [1/1] 1.57ns
.preheader.preheader:26  store i8 %line_buffer_V_2_load, i8* %window_V_2_6_loc_1

ST_3: stg_292 [1/1] 1.57ns
.preheader.preheader:27  store i8 %line_buffer_V_3_load, i8* %window_V_3_6_loc_1

ST_3: stg_293 [1/1] 1.57ns
.preheader.preheader:28  store i8 %line_buffer_V_4_load, i8* %window_V_4_6_loc_1

ST_3: stg_294 [1/1] 1.57ns
.preheader.preheader:29  store i8 %line_buffer_V_5_load, i8* %window_V_5_6_loc_1

ST_3: stg_295 [1/1] 0.00ns
.preheader.preheader:30  br label %.loopexit

ST_3: tmp_12 [1/1] 0.00ns
:2  %tmp_12 = zext i10 %col_mid2 to i64

ST_3: line_buffer_V_5_addr_1 [1/1] 0.00ns
:3  %line_buffer_V_5_addr_1 = getelementptr [640 x i8]* @line_buffer_V_5, i64 0, i64 %tmp_12

ST_3: stg_298 [1/1] 2.71ns
:4  store i8 %in_temp_V, i8* %line_buffer_V_5_addr_1, align 1

ST_3: stg_299 [1/1] 1.57ns
:5  store i8 %in_temp_V, i8* %in_temp_V_1

ST_3: stg_300 [1/1] 0.00ns
:6  br label %.loopexit._crit_edge


 <State 4>: 22.64ns
ST_4: window_V_0_1_load [1/1] 0.00ns
.preheader45.preheader.0:0  %window_V_0_1_load = load i8* @window_V_0_1, align 1

ST_4: window_V_0_2_load [1/1] 0.00ns
.preheader45.preheader.0:1  %window_V_0_2_load = load i8* @window_V_0_2, align 2

ST_4: stg_303 [1/1] 0.00ns
.preheader45.preheader.0:2  store i8 %window_V_0_2_load, i8* @window_V_0_1, align 1

ST_4: window_V_0_3_load [1/1] 0.00ns
.preheader45.preheader.0:3  %window_V_0_3_load = load i8* @window_V_0_3, align 1

ST_4: stg_305 [1/1] 0.00ns
.preheader45.preheader.0:4  store i8 %window_V_0_3_load, i8* @window_V_0_2, align 2

ST_4: window_V_0_4_load [1/1] 0.00ns
.preheader45.preheader.0:5  %window_V_0_4_load = load i8* @window_V_0_4, align 4

ST_4: stg_307 [1/1] 0.00ns
.preheader45.preheader.0:6  store i8 %window_V_0_4_load, i8* @window_V_0_3, align 1

ST_4: window_V_0_5_load [1/1] 0.00ns
.preheader45.preheader.0:7  %window_V_0_5_load = load i8* @window_V_0_5, align 1

ST_4: stg_309 [1/1] 0.00ns
.preheader45.preheader.0:8  store i8 %window_V_0_5_load, i8* @window_V_0_4, align 4

ST_4: stg_310 [1/1] 0.00ns
.preheader45.preheader.0:9  store i8 %window_V_0_6_loc_1_load, i8* @window_V_0_5, align 1

ST_4: window_V_1_1_load [1/1] 0.00ns
.preheader45.preheader.0:10  %window_V_1_1_load = load i8* @window_V_1_1, align 1

ST_4: window_V_1_2_load [1/1] 0.00ns
.preheader45.preheader.0:11  %window_V_1_2_load = load i8* @window_V_1_2, align 1

ST_4: stg_313 [1/1] 0.00ns
.preheader45.preheader.0:12  store i8 %window_V_1_2_load, i8* @window_V_1_1, align 1

ST_4: window_V_1_3_load [1/1] 0.00ns
.preheader45.preheader.0:13  %window_V_1_3_load = load i8* @window_V_1_3, align 1

ST_4: stg_315 [1/1] 0.00ns
.preheader45.preheader.0:14  store i8 %window_V_1_3_load, i8* @window_V_1_2, align 1

ST_4: window_V_1_4_load [1/1] 0.00ns
.preheader45.preheader.0:15  %window_V_1_4_load = load i8* @window_V_1_4, align 1

ST_4: stg_317 [1/1] 0.00ns
.preheader45.preheader.0:16  store i8 %window_V_1_4_load, i8* @window_V_1_3, align 1

ST_4: window_V_1_5_load [1/1] 0.00ns
.preheader45.preheader.0:17  %window_V_1_5_load = load i8* @window_V_1_5, align 1

ST_4: stg_319 [1/1] 0.00ns
.preheader45.preheader.0:18  store i8 %window_V_1_5_load, i8* @window_V_1_4, align 1

ST_4: stg_320 [1/1] 0.00ns
.preheader45.preheader.0:19  store i8 %window_V_1_6_loc_1_load, i8* @window_V_1_5, align 1

ST_4: window_V_2_1_load [1/1] 0.00ns
.preheader45.preheader.0:20  %window_V_2_1_load = load i8* @window_V_2_1, align 1

ST_4: window_V_2_2_load [1/1] 0.00ns
.preheader45.preheader.0:21  %window_V_2_2_load = load i8* @window_V_2_2, align 2

ST_4: stg_323 [1/1] 0.00ns
.preheader45.preheader.0:22  store i8 %window_V_2_2_load, i8* @window_V_2_1, align 1

ST_4: window_V_2_3_load [1/1] 0.00ns
.preheader45.preheader.0:23  %window_V_2_3_load = load i8* @window_V_2_3, align 1

ST_4: stg_325 [1/1] 0.00ns
.preheader45.preheader.0:24  store i8 %window_V_2_3_load, i8* @window_V_2_2, align 2

ST_4: window_V_2_4_load [1/1] 0.00ns
.preheader45.preheader.0:25  %window_V_2_4_load = load i8* @window_V_2_4, align 2

ST_4: stg_327 [1/1] 0.00ns
.preheader45.preheader.0:26  store i8 %window_V_2_4_load, i8* @window_V_2_3, align 1

ST_4: window_V_2_5_load [1/1] 0.00ns
.preheader45.preheader.0:27  %window_V_2_5_load = load i8* @window_V_2_5, align 1

ST_4: stg_329 [1/1] 0.00ns
.preheader45.preheader.0:28  store i8 %window_V_2_5_load, i8* @window_V_2_4, align 2

ST_4: stg_330 [1/1] 0.00ns
.preheader45.preheader.0:29  store i8 %window_V_2_6_loc_1_load, i8* @window_V_2_5, align 1

ST_4: window_V_3_1_load [1/1] 0.00ns
.preheader45.preheader.0:30  %window_V_3_1_load = load i8* @window_V_3_1, align 1

ST_4: window_V_3_2_load [1/1] 0.00ns
.preheader45.preheader.0:31  %window_V_3_2_load = load i8* @window_V_3_2, align 1

ST_4: stg_333 [1/1] 0.00ns
.preheader45.preheader.0:32  store i8 %window_V_3_2_load, i8* @window_V_3_1, align 1

ST_4: window_V_3_3_load [1/1] 0.00ns
.preheader45.preheader.0:33  %window_V_3_3_load = load i8* @window_V_3_3, align 1

ST_4: stg_335 [1/1] 0.00ns
.preheader45.preheader.0:34  store i8 %window_V_3_3_load, i8* @window_V_3_2, align 1

ST_4: window_V_3_4_load [1/1] 0.00ns
.preheader45.preheader.0:35  %window_V_3_4_load = load i8* @window_V_3_4, align 1

ST_4: stg_337 [1/1] 0.00ns
.preheader45.preheader.0:36  store i8 %window_V_3_4_load, i8* @window_V_3_3, align 1

ST_4: window_V_3_5_load [1/1] 0.00ns
.preheader45.preheader.0:37  %window_V_3_5_load = load i8* @window_V_3_5, align 1

ST_4: stg_339 [1/1] 0.00ns
.preheader45.preheader.0:38  store i8 %window_V_3_5_load, i8* @window_V_3_4, align 1

ST_4: stg_340 [1/1] 0.00ns
.preheader45.preheader.0:39  store i8 %window_V_3_6_loc_1_load, i8* @window_V_3_5, align 1

ST_4: window_V_4_1_load [1/1] 0.00ns
.preheader45.preheader.0:40  %window_V_4_1_load = load i8* @window_V_4_1, align 1

ST_4: window_V_4_2_load [1/1] 0.00ns
.preheader45.preheader.0:41  %window_V_4_2_load = load i8* @window_V_4_2, align 2

ST_4: stg_343 [1/1] 0.00ns
.preheader45.preheader.0:42  store i8 %window_V_4_2_load, i8* @window_V_4_1, align 1

ST_4: window_V_4_3_load [1/1] 0.00ns
.preheader45.preheader.0:43  %window_V_4_3_load = load i8* @window_V_4_3, align 1

ST_4: stg_345 [1/1] 0.00ns
.preheader45.preheader.0:44  store i8 %window_V_4_3_load, i8* @window_V_4_2, align 2

ST_4: window_V_4_4_load [1/1] 0.00ns
.preheader45.preheader.0:45  %window_V_4_4_load = load i8* @window_V_4_4, align 4

ST_4: stg_347 [1/1] 0.00ns
.preheader45.preheader.0:46  store i8 %window_V_4_4_load, i8* @window_V_4_3, align 1

ST_4: window_V_4_5_load [1/1] 0.00ns
.preheader45.preheader.0:47  %window_V_4_5_load = load i8* @window_V_4_5, align 1

ST_4: stg_349 [1/1] 0.00ns
.preheader45.preheader.0:48  store i8 %window_V_4_5_load, i8* @window_V_4_4, align 4

ST_4: stg_350 [1/1] 0.00ns
.preheader45.preheader.0:49  store i8 %window_V_4_6_loc_1_load, i8* @window_V_4_5, align 1

ST_4: window_V_5_1_load [1/1] 0.00ns
.preheader45.preheader.0:50  %window_V_5_1_load = load i8* @window_V_5_1, align 1

ST_4: window_V_5_2_load [1/1] 0.00ns
.preheader45.preheader.0:51  %window_V_5_2_load = load i8* @window_V_5_2, align 1

ST_4: stg_353 [1/1] 0.00ns
.preheader45.preheader.0:52  store i8 %window_V_5_2_load, i8* @window_V_5_1, align 1

ST_4: window_V_5_3_load [1/1] 0.00ns
.preheader45.preheader.0:53  %window_V_5_3_load = load i8* @window_V_5_3, align 1

ST_4: stg_355 [1/1] 0.00ns
.preheader45.preheader.0:54  store i8 %window_V_5_3_load, i8* @window_V_5_2, align 1

ST_4: window_V_5_4_load [1/1] 0.00ns
.preheader45.preheader.0:55  %window_V_5_4_load = load i8* @window_V_5_4, align 1

ST_4: stg_357 [1/1] 0.00ns
.preheader45.preheader.0:56  store i8 %window_V_5_4_load, i8* @window_V_5_3, align 1

ST_4: window_V_5_5_load [1/1] 0.00ns
.preheader45.preheader.0:57  %window_V_5_5_load = load i8* @window_V_5_5, align 1

ST_4: stg_359 [1/1] 0.00ns
.preheader45.preheader.0:58  store i8 %window_V_5_5_load, i8* @window_V_5_4, align 1

ST_4: stg_360 [1/1] 0.00ns
.preheader45.preheader.0:59  store i8 %window_V_5_6_loc_1_load, i8* @window_V_5_5, align 1

ST_4: window_V_6_1_load [1/1] 0.00ns
.preheader45.preheader.0:60  %window_V_6_1_load = load i8* @window_V_6_1, align 1

ST_4: window_V_6_2_load [1/1] 0.00ns
.preheader45.preheader.0:61  %window_V_6_2_load = load i8* @window_V_6_2, align 2

ST_4: stg_363 [1/1] 0.00ns
.preheader45.preheader.0:62  store i8 %window_V_6_2_load, i8* @window_V_6_1, align 1

ST_4: window_V_6_3_load [1/1] 0.00ns
.preheader45.preheader.0:63  %window_V_6_3_load = load i8* @window_V_6_3, align 1

ST_4: stg_365 [1/1] 0.00ns
.preheader45.preheader.0:64  store i8 %window_V_6_3_load, i8* @window_V_6_2, align 2

ST_4: window_V_6_4_load [1/1] 0.00ns
.preheader45.preheader.0:65  %window_V_6_4_load = load i8* @window_V_6_4, align 2

ST_4: stg_367 [1/1] 0.00ns
.preheader45.preheader.0:66  store i8 %window_V_6_4_load, i8* @window_V_6_3, align 1

ST_4: window_V_6_5_load [1/1] 0.00ns
.preheader45.preheader.0:67  %window_V_6_5_load = load i8* @window_V_6_5, align 1

ST_4: stg_369 [1/1] 0.00ns
.preheader45.preheader.0:68  store i8 %window_V_6_5_load, i8* @window_V_6_4, align 2

ST_4: stg_370 [1/1] 0.00ns
.preheader45.preheader.0:69  store i8 %in_temp_V_1_load, i8* @window_V_6_5, align 1

ST_4: in_temp_V_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:0  %in_temp_V_1_load_1 = load i8* %in_temp_V_1

ST_4: window_V_5_6_loc_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:1  %window_V_5_6_loc_1_load_1 = load i8* %window_V_5_6_loc_1

ST_4: window_V_4_6_loc_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:2  %window_V_4_6_loc_1_load_1 = load i8* %window_V_4_6_loc_1

ST_4: window_V_3_6_loc_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:3  %window_V_3_6_loc_1_load_1 = load i8* %window_V_3_6_loc_1

ST_4: window_V_2_6_loc_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:4  %window_V_2_6_loc_1_load_1 = load i8* %window_V_2_6_loc_1

ST_4: window_V_1_6_loc_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:5  %window_V_1_6_loc_1_load_1 = load i8* %window_V_1_6_loc_1

ST_4: window_V_0_6_loc_1_load_1 [1/1] 0.00ns
pixel_weighted_average.exit:6  %window_V_0_6_loc_1_load_1 = load i8* %window_V_0_6_loc_1

ST_4: kernel_sum_V_load [1/1] 0.00ns
pixel_weighted_average.exit:7  %kernel_sum_V_load = load i8* @kernel_sum_V, align 1

ST_4: kernel_off_V_load [1/1] 0.00ns
pixel_weighted_average.exit:8  %kernel_off_V_load = load i8* @kernel_off_V, align 1

ST_4: lhs_V_1 [1/1] 0.00ns
pixel_weighted_average.exit:10  %lhs_V_1 = zext i8 %window_V_0_1_load to i16

ST_4: kernel_V_0_0_load [1/1] 0.00ns
pixel_weighted_average.exit:11  %kernel_V_0_0_load = load i8* @kernel_V_0_0, align 16

ST_4: rhs_V_1 [1/1] 0.00ns
pixel_weighted_average.exit:12  %rhs_V_1 = sext i8 %kernel_V_0_0_load to i16

ST_4: r_V_s [1/1] 5.96ns
pixel_weighted_average.exit:13  %r_V_s = mul i16 %rhs_V_1, %lhs_V_1

ST_4: stg_384 [1/1] 0.00ns
pixel_weighted_average.exit:14  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_s, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_341_cast [1/1] 0.00ns
pixel_weighted_average.exit:16  %tmp_341_cast = sext i16 %r_V_s to i18

ST_4: lhs_V_1_0_1 [1/1] 0.00ns
pixel_weighted_average.exit:18  %lhs_V_1_0_1 = zext i8 %window_V_0_2_load to i16

ST_4: kernel_V_0_1_load [1/1] 0.00ns
pixel_weighted_average.exit:19  %kernel_V_0_1_load = load i8* @kernel_V_0_1, align 1

ST_4: rhs_V_1_0_1 [1/1] 0.00ns
pixel_weighted_average.exit:20  %rhs_V_1_0_1 = sext i8 %kernel_V_0_1_load to i16

ST_4: r_V_2_0_1 [1/1] 5.96ns
pixel_weighted_average.exit:21  %r_V_2_0_1 = mul i16 %rhs_V_1_0_1, %lhs_V_1_0_1

ST_4: stg_390 [1/1] 0.00ns
pixel_weighted_average.exit:22  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_0_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:24  %tmp_34_0_1_cast = sext i16 %r_V_2_0_1 to i17

ST_4: lhs_V_1_0_2 [1/1] 0.00ns
pixel_weighted_average.exit:26  %lhs_V_1_0_2 = zext i8 %window_V_0_3_load to i16

ST_4: kernel_V_0_2_load [1/1] 0.00ns
pixel_weighted_average.exit:27  %kernel_V_0_2_load = load i8* @kernel_V_0_2, align 2

ST_4: rhs_V_1_0_2 [1/1] 0.00ns
pixel_weighted_average.exit:28  %rhs_V_1_0_2 = sext i8 %kernel_V_0_2_load to i16

ST_4: r_V_2_0_2 [1/1] 5.96ns
pixel_weighted_average.exit:29  %r_V_2_0_2 = mul i16 %rhs_V_1_0_2, %lhs_V_1_0_2

ST_4: stg_396 [1/1] 0.00ns
pixel_weighted_average.exit:30  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_0_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:32  %tmp_34_0_2_cast = sext i16 %r_V_2_0_2 to i17

ST_4: lhs_V_1_0_3 [1/1] 0.00ns
pixel_weighted_average.exit:34  %lhs_V_1_0_3 = zext i8 %window_V_0_4_load to i16

ST_4: kernel_V_0_3_load [1/1] 0.00ns
pixel_weighted_average.exit:35  %kernel_V_0_3_load = load i8* @kernel_V_0_3, align 1

ST_4: rhs_V_1_0_3 [1/1] 0.00ns
pixel_weighted_average.exit:36  %rhs_V_1_0_3 = sext i8 %kernel_V_0_3_load to i16

ST_4: r_V_2_0_3 [1/1] 5.96ns
pixel_weighted_average.exit:37  %r_V_2_0_3 = mul i16 %rhs_V_1_0_3, %lhs_V_1_0_3

ST_4: stg_402 [1/1] 0.00ns
pixel_weighted_average.exit:38  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_0_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:40  %tmp_34_0_3_cast = sext i16 %r_V_2_0_3 to i18

ST_4: lhs_V_1_0_4 [1/1] 0.00ns
pixel_weighted_average.exit:42  %lhs_V_1_0_4 = zext i8 %window_V_0_5_load to i16

ST_4: kernel_V_0_4_load [1/1] 0.00ns
pixel_weighted_average.exit:43  %kernel_V_0_4_load = load i8* @kernel_V_0_4, align 4

ST_4: rhs_V_1_0_4 [1/1] 0.00ns
pixel_weighted_average.exit:44  %rhs_V_1_0_4 = sext i8 %kernel_V_0_4_load to i16

ST_4: r_V_2_0_4 [1/1] 5.96ns
pixel_weighted_average.exit:45  %r_V_2_0_4 = mul i16 %rhs_V_1_0_4, %lhs_V_1_0_4

ST_4: stg_408 [1/1] 0.00ns
pixel_weighted_average.exit:46  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_0_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:48  %tmp_34_0_4_cast = sext i16 %r_V_2_0_4 to i17

ST_4: lhs_V_1_0_5 [1/1] 0.00ns
pixel_weighted_average.exit:50  %lhs_V_1_0_5 = zext i8 %window_V_0_6_loc_1_load to i16

ST_4: kernel_V_0_5_load [1/1] 0.00ns
pixel_weighted_average.exit:51  %kernel_V_0_5_load = load i8* @kernel_V_0_5, align 1

ST_4: rhs_V_1_0_5 [1/1] 0.00ns
pixel_weighted_average.exit:52  %rhs_V_1_0_5 = sext i8 %kernel_V_0_5_load to i16

ST_4: r_V_2_0_5 [1/1] 5.96ns
pixel_weighted_average.exit:53  %r_V_2_0_5 = mul i16 %rhs_V_1_0_5, %lhs_V_1_0_5

ST_4: stg_414 [1/1] 0.00ns
pixel_weighted_average.exit:54  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_0_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:56  %tmp_34_0_5_cast = sext i16 %r_V_2_0_5 to i17

ST_4: lhs_V_1_0_6 [1/1] 0.00ns
pixel_weighted_average.exit:58  %lhs_V_1_0_6 = zext i8 %window_V_0_6_loc_1_load_1 to i16

ST_4: kernel_V_0_6_load [1/1] 0.00ns
pixel_weighted_average.exit:59  %kernel_V_0_6_load = load i8* @kernel_V_0_6, align 2

ST_4: rhs_V_1_0_6 [1/1] 0.00ns
pixel_weighted_average.exit:60  %rhs_V_1_0_6 = sext i8 %kernel_V_0_6_load to i16

ST_4: r_V_2_0_6 [1/1] 5.96ns
pixel_weighted_average.exit:61  %r_V_2_0_6 = mul i16 %rhs_V_1_0_6, %lhs_V_1_0_6

ST_4: stg_420 [1/1] 0.00ns
pixel_weighted_average.exit:62  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_0_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:64  %tmp_34_0_6_cast = sext i16 %r_V_2_0_6 to i18

ST_4: lhs_V_1_1 [1/1] 0.00ns
pixel_weighted_average.exit:66  %lhs_V_1_1 = zext i8 %window_V_1_1_load to i16

ST_4: kernel_V_1_0_load [1/1] 0.00ns
pixel_weighted_average.exit:67  %kernel_V_1_0_load = load i8* @kernel_V_1_0, align 1

ST_4: rhs_V_1_1 [1/1] 0.00ns
pixel_weighted_average.exit:68  %rhs_V_1_1 = sext i8 %kernel_V_1_0_load to i16

ST_4: r_V_2_1 [1/1] 5.96ns
pixel_weighted_average.exit:69  %r_V_2_1 = mul i16 %rhs_V_1_1, %lhs_V_1_1

ST_4: stg_426 [1/1] 0.00ns
pixel_weighted_average.exit:70  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:72  %tmp_34_1_cast = sext i16 %r_V_2_1 to i17

ST_4: lhs_V_1_1_1 [1/1] 0.00ns
pixel_weighted_average.exit:74  %lhs_V_1_1_1 = zext i8 %window_V_1_2_load to i16

ST_4: kernel_V_1_1_load [1/1] 0.00ns
pixel_weighted_average.exit:75  %kernel_V_1_1_load = load i8* @kernel_V_1_1, align 1

ST_4: rhs_V_1_1_1 [1/1] 0.00ns
pixel_weighted_average.exit:76  %rhs_V_1_1_1 = sext i8 %kernel_V_1_1_load to i16

ST_4: r_V_2_1_1 [1/1] 5.96ns
pixel_weighted_average.exit:77  %r_V_2_1_1 = mul i16 %rhs_V_1_1_1, %lhs_V_1_1_1

ST_4: stg_432 [1/1] 0.00ns
pixel_weighted_average.exit:78  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:80  %tmp_34_1_1_cast = sext i16 %r_V_2_1_1 to i17

ST_4: lhs_V_1_1_2 [1/1] 0.00ns
pixel_weighted_average.exit:82  %lhs_V_1_1_2 = zext i8 %window_V_1_3_load to i16

ST_4: kernel_V_1_2_load [1/1] 0.00ns
pixel_weighted_average.exit:83  %kernel_V_1_2_load = load i8* @kernel_V_1_2, align 1

ST_4: rhs_V_1_1_2 [1/1] 0.00ns
pixel_weighted_average.exit:84  %rhs_V_1_1_2 = sext i8 %kernel_V_1_2_load to i16

ST_4: r_V_2_1_2 [1/1] 5.96ns
pixel_weighted_average.exit:85  %r_V_2_1_2 = mul i16 %rhs_V_1_1_2, %lhs_V_1_1_2

ST_4: stg_438 [1/1] 0.00ns
pixel_weighted_average.exit:86  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:88  %tmp_34_1_2_cast = sext i16 %r_V_2_1_2 to i18

ST_4: lhs_V_1_1_3 [1/1] 0.00ns
pixel_weighted_average.exit:90  %lhs_V_1_1_3 = zext i8 %window_V_1_4_load to i16

ST_4: kernel_V_1_3_load [1/1] 0.00ns
pixel_weighted_average.exit:91  %kernel_V_1_3_load = load i8* @kernel_V_1_3, align 1

ST_4: rhs_V_1_1_3 [1/1] 0.00ns
pixel_weighted_average.exit:92  %rhs_V_1_1_3 = sext i8 %kernel_V_1_3_load to i16

ST_4: r_V_2_1_3 [1/1] 5.96ns
pixel_weighted_average.exit:93  %r_V_2_1_3 = mul i16 %rhs_V_1_1_3, %lhs_V_1_1_3

ST_4: stg_444 [1/1] 0.00ns
pixel_weighted_average.exit:94  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:96  %tmp_34_1_3_cast = sext i16 %r_V_2_1_3 to i17

ST_4: lhs_V_1_1_4 [1/1] 0.00ns
pixel_weighted_average.exit:98  %lhs_V_1_1_4 = zext i8 %window_V_1_5_load to i16

ST_4: kernel_V_1_4_load [1/1] 0.00ns
pixel_weighted_average.exit:99  %kernel_V_1_4_load = load i8* @kernel_V_1_4, align 1

ST_4: rhs_V_1_1_4 [1/1] 0.00ns
pixel_weighted_average.exit:100  %rhs_V_1_1_4 = sext i8 %kernel_V_1_4_load to i16

ST_4: r_V_2_1_4 [1/1] 5.96ns
pixel_weighted_average.exit:101  %r_V_2_1_4 = mul i16 %rhs_V_1_1_4, %lhs_V_1_1_4

ST_4: stg_450 [1/1] 0.00ns
pixel_weighted_average.exit:102  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:104  %tmp_34_1_4_cast = sext i16 %r_V_2_1_4 to i17

ST_4: lhs_V_1_1_5 [1/1] 0.00ns
pixel_weighted_average.exit:106  %lhs_V_1_1_5 = zext i8 %window_V_1_6_loc_1_load to i16

ST_4: kernel_V_1_5_load [1/1] 0.00ns
pixel_weighted_average.exit:107  %kernel_V_1_5_load = load i8* @kernel_V_1_5, align 1

ST_4: rhs_V_1_1_5 [1/1] 0.00ns
pixel_weighted_average.exit:108  %rhs_V_1_1_5 = sext i8 %kernel_V_1_5_load to i16

ST_4: r_V_2_1_5 [1/1] 5.96ns
pixel_weighted_average.exit:109  %r_V_2_1_5 = mul i16 %rhs_V_1_1_5, %lhs_V_1_1_5

ST_4: stg_456 [1/1] 0.00ns
pixel_weighted_average.exit:110  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:112  %tmp_34_1_5_cast = sext i16 %r_V_2_1_5 to i18

ST_4: lhs_V_1_1_6 [1/1] 0.00ns
pixel_weighted_average.exit:114  %lhs_V_1_1_6 = zext i8 %window_V_1_6_loc_1_load_1 to i16

ST_4: kernel_V_1_6_load [1/1] 0.00ns
pixel_weighted_average.exit:115  %kernel_V_1_6_load = load i8* @kernel_V_1_6, align 1

ST_4: rhs_V_1_1_6 [1/1] 0.00ns
pixel_weighted_average.exit:116  %rhs_V_1_1_6 = sext i8 %kernel_V_1_6_load to i16

ST_4: r_V_2_1_6 [1/1] 5.96ns
pixel_weighted_average.exit:117  %r_V_2_1_6 = mul i16 %rhs_V_1_1_6, %lhs_V_1_1_6

ST_4: stg_462 [1/1] 0.00ns
pixel_weighted_average.exit:118  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_1_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:120  %tmp_34_1_6_cast = sext i16 %r_V_2_1_6 to i17

ST_4: lhs_V_1_2 [1/1] 0.00ns
pixel_weighted_average.exit:122  %lhs_V_1_2 = zext i8 %window_V_2_1_load to i16

ST_4: kernel_V_2_0_load [1/1] 0.00ns
pixel_weighted_average.exit:123  %kernel_V_2_0_load = load i8* @kernel_V_2_0, align 2

ST_4: rhs_V_1_2 [1/1] 0.00ns
pixel_weighted_average.exit:124  %rhs_V_1_2 = sext i8 %kernel_V_2_0_load to i16

ST_4: r_V_2_2 [1/1] 5.96ns
pixel_weighted_average.exit:125  %r_V_2_2 = mul i16 %rhs_V_1_2, %lhs_V_1_2

ST_4: stg_468 [1/1] 0.00ns
pixel_weighted_average.exit:126  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:128  %tmp_34_2_cast = sext i16 %r_V_2_2 to i17

ST_4: lhs_V_1_2_1 [1/1] 0.00ns
pixel_weighted_average.exit:130  %lhs_V_1_2_1 = zext i8 %window_V_2_2_load to i16

ST_4: kernel_V_2_1_load [1/1] 0.00ns
pixel_weighted_average.exit:131  %kernel_V_2_1_load = load i8* @kernel_V_2_1, align 1

ST_4: rhs_V_1_2_1 [1/1] 0.00ns
pixel_weighted_average.exit:132  %rhs_V_1_2_1 = sext i8 %kernel_V_2_1_load to i16

ST_4: r_V_2_2_1 [1/1] 5.96ns
pixel_weighted_average.exit:133  %r_V_2_2_1 = mul i16 %rhs_V_1_2_1, %lhs_V_1_2_1

ST_4: stg_474 [1/1] 0.00ns
pixel_weighted_average.exit:134  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:136  %tmp_34_2_1_cast = sext i16 %r_V_2_2_1 to i18

ST_4: lhs_V_1_2_2 [1/1] 0.00ns
pixel_weighted_average.exit:138  %lhs_V_1_2_2 = zext i8 %window_V_2_3_load to i16

ST_4: kernel_V_2_2_load [1/1] 0.00ns
pixel_weighted_average.exit:139  %kernel_V_2_2_load = load i8* @kernel_V_2_2, align 2

ST_4: rhs_V_1_2_2 [1/1] 0.00ns
pixel_weighted_average.exit:140  %rhs_V_1_2_2 = sext i8 %kernel_V_2_2_load to i16

ST_4: r_V_2_2_2 [1/1] 5.96ns
pixel_weighted_average.exit:141  %r_V_2_2_2 = mul i16 %rhs_V_1_2_2, %lhs_V_1_2_2

ST_4: stg_480 [1/1] 0.00ns
pixel_weighted_average.exit:142  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:144  %tmp_34_2_2_cast = sext i16 %r_V_2_2_2 to i17

ST_4: lhs_V_1_2_3 [1/1] 0.00ns
pixel_weighted_average.exit:146  %lhs_V_1_2_3 = zext i8 %window_V_2_4_load to i16

ST_4: kernel_V_2_3_load [1/1] 0.00ns
pixel_weighted_average.exit:147  %kernel_V_2_3_load = load i8* @kernel_V_2_3, align 1

ST_4: rhs_V_1_2_3 [1/1] 0.00ns
pixel_weighted_average.exit:148  %rhs_V_1_2_3 = sext i8 %kernel_V_2_3_load to i16

ST_4: r_V_2_2_3 [1/1] 5.96ns
pixel_weighted_average.exit:149  %r_V_2_2_3 = mul i16 %rhs_V_1_2_3, %lhs_V_1_2_3

ST_4: stg_486 [1/1] 0.00ns
pixel_weighted_average.exit:150  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:152  %tmp_34_2_3_cast = sext i16 %r_V_2_2_3 to i17

ST_4: lhs_V_1_2_4 [1/1] 0.00ns
pixel_weighted_average.exit:154  %lhs_V_1_2_4 = zext i8 %window_V_2_5_load to i16

ST_4: kernel_V_2_4_load [1/1] 0.00ns
pixel_weighted_average.exit:155  %kernel_V_2_4_load = load i8* @kernel_V_2_4, align 2

ST_4: rhs_V_1_2_4 [1/1] 0.00ns
pixel_weighted_average.exit:156  %rhs_V_1_2_4 = sext i8 %kernel_V_2_4_load to i16

ST_4: r_V_2_2_4 [1/1] 5.96ns
pixel_weighted_average.exit:157  %r_V_2_2_4 = mul i16 %rhs_V_1_2_4, %lhs_V_1_2_4

ST_4: stg_492 [1/1] 0.00ns
pixel_weighted_average.exit:158  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:160  %tmp_34_2_4_cast = sext i16 %r_V_2_2_4 to i18

ST_4: lhs_V_1_2_5 [1/1] 0.00ns
pixel_weighted_average.exit:162  %lhs_V_1_2_5 = zext i8 %window_V_2_6_loc_1_load to i16

ST_4: kernel_V_2_5_load [1/1] 0.00ns
pixel_weighted_average.exit:163  %kernel_V_2_5_load = load i8* @kernel_V_2_5, align 1

ST_4: rhs_V_1_2_5 [1/1] 0.00ns
pixel_weighted_average.exit:164  %rhs_V_1_2_5 = sext i8 %kernel_V_2_5_load to i16

ST_4: r_V_2_2_5 [1/1] 5.96ns
pixel_weighted_average.exit:165  %r_V_2_2_5 = mul i16 %rhs_V_1_2_5, %lhs_V_1_2_5

ST_4: stg_498 [1/1] 0.00ns
pixel_weighted_average.exit:166  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:168  %tmp_34_2_5_cast = sext i16 %r_V_2_2_5 to i17

ST_4: lhs_V_1_2_6 [1/1] 0.00ns
pixel_weighted_average.exit:170  %lhs_V_1_2_6 = zext i8 %window_V_2_6_loc_1_load_1 to i16

ST_4: kernel_V_2_6_load [1/1] 0.00ns
pixel_weighted_average.exit:171  %kernel_V_2_6_load = load i8* @kernel_V_2_6, align 2

ST_4: rhs_V_1_2_6 [1/1] 0.00ns
pixel_weighted_average.exit:172  %rhs_V_1_2_6 = sext i8 %kernel_V_2_6_load to i16

ST_4: r_V_2_2_6 [1/1] 5.96ns
pixel_weighted_average.exit:173  %r_V_2_2_6 = mul i16 %rhs_V_1_2_6, %lhs_V_1_2_6

ST_4: stg_504 [1/1] 0.00ns
pixel_weighted_average.exit:174  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_2_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:176  %tmp_34_2_6_cast = sext i16 %r_V_2_2_6 to i17

ST_4: lhs_V_1_3 [1/1] 0.00ns
pixel_weighted_average.exit:178  %lhs_V_1_3 = zext i8 %window_V_3_1_load to i16

ST_4: kernel_V_3_0_load [1/1] 0.00ns
pixel_weighted_average.exit:179  %kernel_V_3_0_load = load i8* @kernel_V_3_0, align 1

ST_4: rhs_V_1_3 [1/1] 0.00ns
pixel_weighted_average.exit:180  %rhs_V_1_3 = sext i8 %kernel_V_3_0_load to i16

ST_4: r_V_2_3 [1/1] 5.96ns
pixel_weighted_average.exit:181  %r_V_2_3 = mul i16 %rhs_V_1_3, %lhs_V_1_3

ST_4: stg_510 [1/1] 0.00ns
pixel_weighted_average.exit:182  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:184  %tmp_34_3_cast = sext i16 %r_V_2_3 to i18

ST_4: lhs_V_1_3_1 [1/1] 0.00ns
pixel_weighted_average.exit:186  %lhs_V_1_3_1 = zext i8 %window_V_3_2_load to i16

ST_4: kernel_V_3_1_load [1/1] 0.00ns
pixel_weighted_average.exit:187  %kernel_V_3_1_load = load i8* @kernel_V_3_1, align 1

ST_4: rhs_V_1_3_1 [1/1] 0.00ns
pixel_weighted_average.exit:188  %rhs_V_1_3_1 = sext i8 %kernel_V_3_1_load to i16

ST_4: r_V_2_3_1 [1/1] 5.96ns
pixel_weighted_average.exit:189  %r_V_2_3_1 = mul i16 %rhs_V_1_3_1, %lhs_V_1_3_1

ST_4: stg_516 [1/1] 0.00ns
pixel_weighted_average.exit:190  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:192  %tmp_34_3_1_cast = sext i16 %r_V_2_3_1 to i17

ST_4: lhs_V_1_3_2 [1/1] 0.00ns
pixel_weighted_average.exit:194  %lhs_V_1_3_2 = zext i8 %window_V_3_3_load to i16

ST_4: kernel_V_3_2_load [1/1] 0.00ns
pixel_weighted_average.exit:195  %kernel_V_3_2_load = load i8* @kernel_V_3_2, align 1

ST_4: rhs_V_1_3_2 [1/1] 0.00ns
pixel_weighted_average.exit:196  %rhs_V_1_3_2 = sext i8 %kernel_V_3_2_load to i16

ST_4: r_V_2_3_2 [1/1] 5.96ns
pixel_weighted_average.exit:197  %r_V_2_3_2 = mul i16 %rhs_V_1_3_2, %lhs_V_1_3_2

ST_4: stg_522 [1/1] 0.00ns
pixel_weighted_average.exit:198  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:200  %tmp_34_3_2_cast = sext i16 %r_V_2_3_2 to i17

ST_4: lhs_V_1_3_3 [1/1] 0.00ns
pixel_weighted_average.exit:202  %lhs_V_1_3_3 = zext i8 %window_V_3_4_load to i16

ST_4: kernel_V_3_3_load [1/1] 0.00ns
pixel_weighted_average.exit:203  %kernel_V_3_3_load = load i8* @kernel_V_3_3, align 1

ST_4: rhs_V_1_3_3 [1/1] 0.00ns
pixel_weighted_average.exit:204  %rhs_V_1_3_3 = sext i8 %kernel_V_3_3_load to i16

ST_4: r_V_2_3_3 [1/1] 5.96ns
pixel_weighted_average.exit:205  %r_V_2_3_3 = mul i16 %rhs_V_1_3_3, %lhs_V_1_3_3

ST_4: stg_528 [1/1] 0.00ns
pixel_weighted_average.exit:206  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:208  %tmp_34_3_3_cast = sext i16 %r_V_2_3_3 to i18

ST_4: lhs_V_1_3_4 [1/1] 0.00ns
pixel_weighted_average.exit:210  %lhs_V_1_3_4 = zext i8 %window_V_3_5_load to i16

ST_4: kernel_V_3_4_load [1/1] 0.00ns
pixel_weighted_average.exit:211  %kernel_V_3_4_load = load i8* @kernel_V_3_4, align 1

ST_4: rhs_V_1_3_4 [1/1] 0.00ns
pixel_weighted_average.exit:212  %rhs_V_1_3_4 = sext i8 %kernel_V_3_4_load to i16

ST_4: r_V_2_3_4 [1/1] 5.96ns
pixel_weighted_average.exit:213  %r_V_2_3_4 = mul i16 %rhs_V_1_3_4, %lhs_V_1_3_4

ST_4: stg_534 [1/1] 0.00ns
pixel_weighted_average.exit:214  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:216  %tmp_34_3_4_cast = sext i16 %r_V_2_3_4 to i17

ST_4: lhs_V_1_3_5 [1/1] 0.00ns
pixel_weighted_average.exit:218  %lhs_V_1_3_5 = zext i8 %window_V_3_6_loc_1_load to i16

ST_4: kernel_V_3_5_load [1/1] 0.00ns
pixel_weighted_average.exit:219  %kernel_V_3_5_load = load i8* @kernel_V_3_5, align 1

ST_4: rhs_V_1_3_5 [1/1] 0.00ns
pixel_weighted_average.exit:220  %rhs_V_1_3_5 = sext i8 %kernel_V_3_5_load to i16

ST_4: r_V_2_3_5 [1/1] 5.96ns
pixel_weighted_average.exit:221  %r_V_2_3_5 = mul i16 %rhs_V_1_3_5, %lhs_V_1_3_5

ST_4: stg_540 [1/1] 0.00ns
pixel_weighted_average.exit:222  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:224  %tmp_34_3_5_cast = sext i16 %r_V_2_3_5 to i17

ST_4: lhs_V_1_3_6 [1/1] 0.00ns
pixel_weighted_average.exit:226  %lhs_V_1_3_6 = zext i8 %window_V_3_6_loc_1_load_1 to i16

ST_4: kernel_V_3_6_load [1/1] 0.00ns
pixel_weighted_average.exit:227  %kernel_V_3_6_load = load i8* @kernel_V_3_6, align 1

ST_4: rhs_V_1_3_6 [1/1] 0.00ns
pixel_weighted_average.exit:228  %rhs_V_1_3_6 = sext i8 %kernel_V_3_6_load to i16

ST_4: r_V_2_3_6 [1/1] 5.96ns
pixel_weighted_average.exit:229  %r_V_2_3_6 = mul i16 %rhs_V_1_3_6, %lhs_V_1_3_6

ST_4: stg_546 [1/1] 0.00ns
pixel_weighted_average.exit:230  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_3_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:232  %tmp_34_3_6_cast = sext i16 %r_V_2_3_6 to i18

ST_4: lhs_V_1_4 [1/1] 0.00ns
pixel_weighted_average.exit:234  %lhs_V_1_4 = zext i8 %window_V_4_1_load to i16

ST_4: kernel_V_4_0_load [1/1] 0.00ns
pixel_weighted_average.exit:235  %kernel_V_4_0_load = load i8* @kernel_V_4_0, align 4

ST_4: rhs_V_1_4 [1/1] 0.00ns
pixel_weighted_average.exit:236  %rhs_V_1_4 = sext i8 %kernel_V_4_0_load to i16

ST_4: r_V_2_4 [1/1] 5.96ns
pixel_weighted_average.exit:237  %r_V_2_4 = mul i16 %rhs_V_1_4, %lhs_V_1_4

ST_4: stg_552 [1/1] 0.00ns
pixel_weighted_average.exit:238  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:240  %tmp_34_4_cast = sext i16 %r_V_2_4 to i17

ST_4: lhs_V_1_4_1 [1/1] 0.00ns
pixel_weighted_average.exit:242  %lhs_V_1_4_1 = zext i8 %window_V_4_2_load to i16

ST_4: kernel_V_4_1_load [1/1] 0.00ns
pixel_weighted_average.exit:243  %kernel_V_4_1_load = load i8* @kernel_V_4_1, align 1

ST_4: rhs_V_1_4_1 [1/1] 0.00ns
pixel_weighted_average.exit:244  %rhs_V_1_4_1 = sext i8 %kernel_V_4_1_load to i16

ST_4: r_V_2_4_1 [1/1] 5.96ns
pixel_weighted_average.exit:245  %r_V_2_4_1 = mul i16 %rhs_V_1_4_1, %lhs_V_1_4_1

ST_4: stg_558 [1/1] 0.00ns
pixel_weighted_average.exit:246  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:248  %tmp_34_4_1_cast = sext i16 %r_V_2_4_1 to i17

ST_4: lhs_V_1_4_2 [1/1] 0.00ns
pixel_weighted_average.exit:250  %lhs_V_1_4_2 = zext i8 %window_V_4_3_load to i16

ST_4: kernel_V_4_2_load [1/1] 0.00ns
pixel_weighted_average.exit:251  %kernel_V_4_2_load = load i8* @kernel_V_4_2, align 2

ST_4: rhs_V_1_4_2 [1/1] 0.00ns
pixel_weighted_average.exit:252  %rhs_V_1_4_2 = sext i8 %kernel_V_4_2_load to i16

ST_4: r_V_2_4_2 [1/1] 5.96ns
pixel_weighted_average.exit:253  %r_V_2_4_2 = mul i16 %rhs_V_1_4_2, %lhs_V_1_4_2

ST_4: stg_564 [1/1] 0.00ns
pixel_weighted_average.exit:254  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:256  %tmp_34_4_2_cast = sext i16 %r_V_2_4_2 to i18

ST_4: lhs_V_1_4_3 [1/1] 0.00ns
pixel_weighted_average.exit:258  %lhs_V_1_4_3 = zext i8 %window_V_4_4_load to i16

ST_4: kernel_V_4_3_load [1/1] 0.00ns
pixel_weighted_average.exit:259  %kernel_V_4_3_load = load i8* @kernel_V_4_3, align 1

ST_4: rhs_V_1_4_3 [1/1] 0.00ns
pixel_weighted_average.exit:260  %rhs_V_1_4_3 = sext i8 %kernel_V_4_3_load to i16

ST_4: r_V_2_4_3 [1/1] 5.96ns
pixel_weighted_average.exit:261  %r_V_2_4_3 = mul i16 %rhs_V_1_4_3, %lhs_V_1_4_3

ST_4: stg_570 [1/1] 0.00ns
pixel_weighted_average.exit:262  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:264  %tmp_34_4_3_cast = sext i16 %r_V_2_4_3 to i17

ST_4: lhs_V_1_4_4 [1/1] 0.00ns
pixel_weighted_average.exit:266  %lhs_V_1_4_4 = zext i8 %window_V_4_5_load to i16

ST_4: kernel_V_4_4_load [1/1] 0.00ns
pixel_weighted_average.exit:267  %kernel_V_4_4_load = load i8* @kernel_V_4_4, align 4

ST_4: rhs_V_1_4_4 [1/1] 0.00ns
pixel_weighted_average.exit:268  %rhs_V_1_4_4 = sext i8 %kernel_V_4_4_load to i16

ST_4: r_V_2_4_4 [1/1] 5.96ns
pixel_weighted_average.exit:269  %r_V_2_4_4 = mul i16 %rhs_V_1_4_4, %lhs_V_1_4_4

ST_4: stg_576 [1/1] 0.00ns
pixel_weighted_average.exit:270  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:272  %tmp_34_4_4_cast = sext i16 %r_V_2_4_4 to i17

ST_4: lhs_V_1_4_5 [1/1] 0.00ns
pixel_weighted_average.exit:274  %lhs_V_1_4_5 = zext i8 %window_V_4_6_loc_1_load to i16

ST_4: kernel_V_4_5_load [1/1] 0.00ns
pixel_weighted_average.exit:275  %kernel_V_4_5_load = load i8* @kernel_V_4_5, align 1

ST_4: rhs_V_1_4_5 [1/1] 0.00ns
pixel_weighted_average.exit:276  %rhs_V_1_4_5 = sext i8 %kernel_V_4_5_load to i16

ST_4: r_V_2_4_5 [1/1] 5.96ns
pixel_weighted_average.exit:277  %r_V_2_4_5 = mul i16 %rhs_V_1_4_5, %lhs_V_1_4_5

ST_4: stg_582 [1/1] 0.00ns
pixel_weighted_average.exit:278  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:280  %tmp_34_4_5_cast = sext i16 %r_V_2_4_5 to i18

ST_4: lhs_V_1_4_6 [1/1] 0.00ns
pixel_weighted_average.exit:282  %lhs_V_1_4_6 = zext i8 %window_V_4_6_loc_1_load_1 to i16

ST_4: kernel_V_4_6_load [1/1] 0.00ns
pixel_weighted_average.exit:283  %kernel_V_4_6_load = load i8* @kernel_V_4_6, align 2

ST_4: rhs_V_1_4_6 [1/1] 0.00ns
pixel_weighted_average.exit:284  %rhs_V_1_4_6 = sext i8 %kernel_V_4_6_load to i16

ST_4: r_V_2_4_6 [1/1] 5.96ns
pixel_weighted_average.exit:285  %r_V_2_4_6 = mul i16 %rhs_V_1_4_6, %lhs_V_1_4_6

ST_4: stg_588 [1/1] 0.00ns
pixel_weighted_average.exit:286  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_4_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:288  %tmp_34_4_6_cast = sext i16 %r_V_2_4_6 to i17

ST_4: lhs_V_1_5 [1/1] 0.00ns
pixel_weighted_average.exit:290  %lhs_V_1_5 = zext i8 %window_V_5_1_load to i16

ST_4: kernel_V_5_0_load [1/1] 0.00ns
pixel_weighted_average.exit:291  %kernel_V_5_0_load = load i8* @kernel_V_5_0, align 1

ST_4: rhs_V_1_5 [1/1] 0.00ns
pixel_weighted_average.exit:292  %rhs_V_1_5 = sext i8 %kernel_V_5_0_load to i16

ST_4: r_V_2_5 [1/1] 5.96ns
pixel_weighted_average.exit:293  %r_V_2_5 = mul i16 %rhs_V_1_5, %lhs_V_1_5

ST_4: stg_594 [1/1] 0.00ns
pixel_weighted_average.exit:294  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:296  %tmp_34_5_cast = sext i16 %r_V_2_5 to i17

ST_4: lhs_V_1_5_1 [1/1] 0.00ns
pixel_weighted_average.exit:298  %lhs_V_1_5_1 = zext i8 %window_V_5_2_load to i16

ST_4: kernel_V_5_1_load [1/1] 0.00ns
pixel_weighted_average.exit:299  %kernel_V_5_1_load = load i8* @kernel_V_5_1, align 1

ST_4: rhs_V_1_5_1 [1/1] 0.00ns
pixel_weighted_average.exit:300  %rhs_V_1_5_1 = sext i8 %kernel_V_5_1_load to i16

ST_4: r_V_2_5_1 [1/1] 5.96ns
pixel_weighted_average.exit:301  %r_V_2_5_1 = mul i16 %rhs_V_1_5_1, %lhs_V_1_5_1

ST_4: stg_600 [1/1] 0.00ns
pixel_weighted_average.exit:302  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:304  %tmp_34_5_1_cast = sext i16 %r_V_2_5_1 to i18

ST_4: lhs_V_1_5_2 [1/1] 0.00ns
pixel_weighted_average.exit:306  %lhs_V_1_5_2 = zext i8 %window_V_5_3_load to i16

ST_4: kernel_V_5_2_load [1/1] 0.00ns
pixel_weighted_average.exit:307  %kernel_V_5_2_load = load i8* @kernel_V_5_2, align 1

ST_4: rhs_V_1_5_2 [1/1] 0.00ns
pixel_weighted_average.exit:308  %rhs_V_1_5_2 = sext i8 %kernel_V_5_2_load to i16

ST_4: r_V_2_5_2 [1/1] 5.96ns
pixel_weighted_average.exit:309  %r_V_2_5_2 = mul i16 %rhs_V_1_5_2, %lhs_V_1_5_2

ST_4: stg_606 [1/1] 0.00ns
pixel_weighted_average.exit:310  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:312  %tmp_34_5_2_cast = sext i16 %r_V_2_5_2 to i17

ST_4: lhs_V_1_5_3 [1/1] 0.00ns
pixel_weighted_average.exit:314  %lhs_V_1_5_3 = zext i8 %window_V_5_4_load to i16

ST_4: kernel_V_5_3_load [1/1] 0.00ns
pixel_weighted_average.exit:315  %kernel_V_5_3_load = load i8* @kernel_V_5_3, align 1

ST_4: rhs_V_1_5_3 [1/1] 0.00ns
pixel_weighted_average.exit:316  %rhs_V_1_5_3 = sext i8 %kernel_V_5_3_load to i16

ST_4: r_V_2_5_3 [1/1] 5.96ns
pixel_weighted_average.exit:317  %r_V_2_5_3 = mul i16 %rhs_V_1_5_3, %lhs_V_1_5_3

ST_4: stg_612 [1/1] 0.00ns
pixel_weighted_average.exit:318  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:320  %tmp_34_5_3_cast = sext i16 %r_V_2_5_3 to i17

ST_4: lhs_V_1_5_4 [1/1] 0.00ns
pixel_weighted_average.exit:322  %lhs_V_1_5_4 = zext i8 %window_V_5_5_load to i16

ST_4: kernel_V_5_4_load [1/1] 0.00ns
pixel_weighted_average.exit:323  %kernel_V_5_4_load = load i8* @kernel_V_5_4, align 1

ST_4: rhs_V_1_5_4 [1/1] 0.00ns
pixel_weighted_average.exit:324  %rhs_V_1_5_4 = sext i8 %kernel_V_5_4_load to i16

ST_4: r_V_2_5_4 [1/1] 5.96ns
pixel_weighted_average.exit:325  %r_V_2_5_4 = mul i16 %rhs_V_1_5_4, %lhs_V_1_5_4

ST_4: stg_618 [1/1] 0.00ns
pixel_weighted_average.exit:326  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:328  %tmp_34_5_4_cast = sext i16 %r_V_2_5_4 to i18

ST_4: lhs_V_1_5_5 [1/1] 0.00ns
pixel_weighted_average.exit:330  %lhs_V_1_5_5 = zext i8 %window_V_5_6_loc_1_load to i16

ST_4: kernel_V_5_5_load [1/1] 0.00ns
pixel_weighted_average.exit:331  %kernel_V_5_5_load = load i8* @kernel_V_5_5, align 1

ST_4: rhs_V_1_5_5 [1/1] 0.00ns
pixel_weighted_average.exit:332  %rhs_V_1_5_5 = sext i8 %kernel_V_5_5_load to i16

ST_4: r_V_2_5_5 [1/1] 5.96ns
pixel_weighted_average.exit:333  %r_V_2_5_5 = mul i16 %rhs_V_1_5_5, %lhs_V_1_5_5

ST_4: stg_624 [1/1] 0.00ns
pixel_weighted_average.exit:334  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:336  %tmp_34_5_5_cast = sext i16 %r_V_2_5_5 to i17

ST_4: lhs_V_1_5_6 [1/1] 0.00ns
pixel_weighted_average.exit:338  %lhs_V_1_5_6 = zext i8 %window_V_5_6_loc_1_load_1 to i16

ST_4: kernel_V_5_6_load [1/1] 0.00ns
pixel_weighted_average.exit:339  %kernel_V_5_6_load = load i8* @kernel_V_5_6, align 1

ST_4: rhs_V_1_5_6 [1/1] 0.00ns
pixel_weighted_average.exit:340  %rhs_V_1_5_6 = sext i8 %kernel_V_5_6_load to i16

ST_4: r_V_2_5_6 [1/1] 5.96ns
pixel_weighted_average.exit:341  %r_V_2_5_6 = mul i16 %rhs_V_1_5_6, %lhs_V_1_5_6

ST_4: stg_630 [1/1] 0.00ns
pixel_weighted_average.exit:342  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_5_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:344  %tmp_34_5_6_cast = sext i16 %r_V_2_5_6 to i17

ST_4: lhs_V_1_6 [1/1] 0.00ns
pixel_weighted_average.exit:346  %lhs_V_1_6 = zext i8 %window_V_6_1_load to i16

ST_4: kernel_V_6_0_load [1/1] 0.00ns
pixel_weighted_average.exit:347  %kernel_V_6_0_load = load i8* @kernel_V_6_0, align 2

ST_4: rhs_V_1_6 [1/1] 0.00ns
pixel_weighted_average.exit:348  %rhs_V_1_6 = sext i8 %kernel_V_6_0_load to i16

ST_4: r_V_2_6 [1/1] 5.96ns
pixel_weighted_average.exit:349  %r_V_2_6 = mul i16 %rhs_V_1_6, %lhs_V_1_6

ST_4: stg_636 [1/1] 0.00ns
pixel_weighted_average.exit:350  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:352  %tmp_34_6_cast = sext i16 %r_V_2_6 to i18

ST_4: lhs_V_1_6_1 [1/1] 0.00ns
pixel_weighted_average.exit:354  %lhs_V_1_6_1 = zext i8 %window_V_6_2_load to i16

ST_4: kernel_V_6_1_load [1/1] 0.00ns
pixel_weighted_average.exit:355  %kernel_V_6_1_load = load i8* @kernel_V_6_1, align 1

ST_4: rhs_V_1_6_1 [1/1] 0.00ns
pixel_weighted_average.exit:356  %rhs_V_1_6_1 = sext i8 %kernel_V_6_1_load to i16

ST_4: r_V_2_6_1 [1/1] 5.96ns
pixel_weighted_average.exit:357  %r_V_2_6_1 = mul i16 %rhs_V_1_6_1, %lhs_V_1_6_1

ST_4: stg_642 [1/1] 0.00ns
pixel_weighted_average.exit:358  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_1_cast [1/1] 0.00ns
pixel_weighted_average.exit:360  %tmp_34_6_1_cast = sext i16 %r_V_2_6_1 to i17

ST_4: lhs_V_1_6_2 [1/1] 0.00ns
pixel_weighted_average.exit:362  %lhs_V_1_6_2 = zext i8 %window_V_6_3_load to i16

ST_4: kernel_V_6_2_load [1/1] 0.00ns
pixel_weighted_average.exit:363  %kernel_V_6_2_load = load i8* @kernel_V_6_2, align 2

ST_4: rhs_V_1_6_2 [1/1] 0.00ns
pixel_weighted_average.exit:364  %rhs_V_1_6_2 = sext i8 %kernel_V_6_2_load to i16

ST_4: r_V_2_6_2 [1/1] 5.96ns
pixel_weighted_average.exit:365  %r_V_2_6_2 = mul i16 %rhs_V_1_6_2, %lhs_V_1_6_2

ST_4: stg_648 [1/1] 0.00ns
pixel_weighted_average.exit:366  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_2_cast [1/1] 0.00ns
pixel_weighted_average.exit:368  %tmp_34_6_2_cast = sext i16 %r_V_2_6_2 to i17

ST_4: lhs_V_1_6_3 [1/1] 0.00ns
pixel_weighted_average.exit:370  %lhs_V_1_6_3 = zext i8 %window_V_6_4_load to i16

ST_4: kernel_V_6_3_load [1/1] 0.00ns
pixel_weighted_average.exit:371  %kernel_V_6_3_load = load i8* @kernel_V_6_3, align 1

ST_4: rhs_V_1_6_3 [1/1] 0.00ns
pixel_weighted_average.exit:372  %rhs_V_1_6_3 = sext i8 %kernel_V_6_3_load to i16

ST_4: r_V_2_6_3 [1/1] 5.96ns
pixel_weighted_average.exit:373  %r_V_2_6_3 = mul i16 %rhs_V_1_6_3, %lhs_V_1_6_3

ST_4: stg_654 [1/1] 0.00ns
pixel_weighted_average.exit:374  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_3_cast [1/1] 0.00ns
pixel_weighted_average.exit:376  %tmp_34_6_3_cast = sext i16 %r_V_2_6_3 to i17

ST_4: lhs_V_1_6_4 [1/1] 0.00ns
pixel_weighted_average.exit:378  %lhs_V_1_6_4 = zext i8 %window_V_6_5_load to i16

ST_4: kernel_V_6_4_load [1/1] 0.00ns
pixel_weighted_average.exit:379  %kernel_V_6_4_load = load i8* @kernel_V_6_4, align 2

ST_4: rhs_V_1_6_4 [1/1] 0.00ns
pixel_weighted_average.exit:380  %rhs_V_1_6_4 = sext i8 %kernel_V_6_4_load to i16

ST_4: r_V_2_6_4 [1/1] 5.96ns
pixel_weighted_average.exit:381  %r_V_2_6_4 = mul i16 %rhs_V_1_6_4, %lhs_V_1_6_4

ST_4: stg_660 [1/1] 0.00ns
pixel_weighted_average.exit:382  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_4_cast [1/1] 0.00ns
pixel_weighted_average.exit:384  %tmp_34_6_4_cast = sext i16 %r_V_2_6_4 to i17

ST_4: lhs_V_1_6_5 [1/1] 0.00ns
pixel_weighted_average.exit:386  %lhs_V_1_6_5 = zext i8 %in_temp_V_1_load to i16

ST_4: kernel_V_6_5_load [1/1] 0.00ns
pixel_weighted_average.exit:387  %kernel_V_6_5_load = load i8* @kernel_V_6_5, align 1

ST_4: rhs_V_1_6_5 [1/1] 0.00ns
pixel_weighted_average.exit:388  %rhs_V_1_6_5 = sext i8 %kernel_V_6_5_load to i16

ST_4: r_V_2_6_5 [1/1] 5.96ns
pixel_weighted_average.exit:389  %r_V_2_6_5 = mul i16 %rhs_V_1_6_5, %lhs_V_1_6_5

ST_4: stg_666 [1/1] 0.00ns
pixel_weighted_average.exit:390  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_5_cast [1/1] 0.00ns
pixel_weighted_average.exit:392  %tmp_34_6_5_cast = sext i16 %r_V_2_6_5 to i17

ST_4: lhs_V_1_6_6 [1/1] 0.00ns
pixel_weighted_average.exit:394  %lhs_V_1_6_6 = zext i8 %in_temp_V_1_load_1 to i16

ST_4: kernel_V_6_6_load [1/1] 0.00ns
pixel_weighted_average.exit:395  %kernel_V_6_6_load = load i8* @kernel_V_6_6, align 2

ST_4: rhs_V_1_6_6 [1/1] 0.00ns
pixel_weighted_average.exit:396  %rhs_V_1_6_6 = sext i8 %kernel_V_6_6_load to i16

ST_4: r_V_2_6_6 [1/1] 5.96ns
pixel_weighted_average.exit:397  %r_V_2_6_6 = mul i16 %rhs_V_1_6_6, %lhs_V_1_6_6

ST_4: stg_672 [1/1] 0.00ns
pixel_weighted_average.exit:398  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)

ST_4: tmp_34_6_6_cast [1/1] 0.00ns
pixel_weighted_average.exit:400  %tmp_34_6_6_cast = sext i16 %r_V_2_6_6 to i17

ST_4: tmp5 [1/1] 1.96ns
pixel_weighted_average.exit:401  %tmp5 = add i17 %tmp_34_0_2_cast, %tmp_34_0_1_cast

ST_4: tmp5_cast [1/1] 0.00ns
pixel_weighted_average.exit:402  %tmp5_cast = sext i17 %tmp5 to i18

ST_4: tmp4 [1/1] 2.08ns
pixel_weighted_average.exit:403  %tmp4 = add i18 %tmp_341_cast, %tmp5_cast

ST_4: tmp4_cast [1/1] 0.00ns
pixel_weighted_average.exit:404  %tmp4_cast = sext i18 %tmp4 to i19

ST_4: tmp7 [1/1] 1.96ns
pixel_weighted_average.exit:405  %tmp7 = add i17 %tmp_34_0_5_cast, %tmp_34_0_4_cast

ST_4: tmp7_cast [1/1] 0.00ns
pixel_weighted_average.exit:406  %tmp7_cast = sext i17 %tmp7 to i18

ST_4: tmp6 [1/1] 2.08ns
pixel_weighted_average.exit:407  %tmp6 = add i18 %tmp_34_0_3_cast, %tmp7_cast

ST_4: tmp6_cast [1/1] 0.00ns
pixel_weighted_average.exit:408  %tmp6_cast = sext i18 %tmp6 to i19

ST_4: tmp3 [1/1] 2.08ns
pixel_weighted_average.exit:409  %tmp3 = add i19 %tmp4_cast, %tmp6_cast

ST_4: tmp3_cast [1/1] 0.00ns
pixel_weighted_average.exit:410  %tmp3_cast = sext i19 %tmp3 to i20

ST_4: tmp10 [1/1] 1.96ns
pixel_weighted_average.exit:411  %tmp10 = add i17 %tmp_34_1_1_cast, %tmp_34_1_cast

ST_4: tmp10_cast [1/1] 0.00ns
pixel_weighted_average.exit:412  %tmp10_cast = sext i17 %tmp10 to i18

ST_4: tmp9 [1/1] 2.08ns
pixel_weighted_average.exit:413  %tmp9 = add i18 %tmp_34_0_6_cast, %tmp10_cast

ST_4: tmp9_cast [1/1] 0.00ns
pixel_weighted_average.exit:414  %tmp9_cast = sext i18 %tmp9 to i19

ST_4: tmp12 [1/1] 1.96ns
pixel_weighted_average.exit:415  %tmp12 = add i17 %tmp_34_1_4_cast, %tmp_34_1_3_cast

ST_4: tmp12_cast [1/1] 0.00ns
pixel_weighted_average.exit:416  %tmp12_cast = sext i17 %tmp12 to i18

ST_4: tmp11 [1/1] 2.08ns
pixel_weighted_average.exit:417  %tmp11 = add i18 %tmp_34_1_2_cast, %tmp12_cast

ST_4: tmp11_cast [1/1] 0.00ns
pixel_weighted_average.exit:418  %tmp11_cast = sext i18 %tmp11 to i19

ST_4: tmp8 [1/1] 2.08ns
pixel_weighted_average.exit:419  %tmp8 = add i19 %tmp9_cast, %tmp11_cast

ST_4: tmp8_cast [1/1] 0.00ns
pixel_weighted_average.exit:420  %tmp8_cast = sext i19 %tmp8 to i20

ST_4: tmp2 [1/1] 2.08ns
pixel_weighted_average.exit:421  %tmp2 = add i20 %tmp3_cast, %tmp8_cast

ST_4: tmp2_cast [1/1] 0.00ns
pixel_weighted_average.exit:422  %tmp2_cast = sext i20 %tmp2 to i21

ST_4: tmp16 [1/1] 1.96ns
pixel_weighted_average.exit:423  %tmp16 = add i17 %tmp_34_2_cast, %tmp_34_1_6_cast

ST_4: tmp16_cast [1/1] 0.00ns
pixel_weighted_average.exit:424  %tmp16_cast = sext i17 %tmp16 to i18

ST_4: tmp15 [1/1] 2.08ns
pixel_weighted_average.exit:425  %tmp15 = add i18 %tmp_34_1_5_cast, %tmp16_cast

ST_4: tmp15_cast [1/1] 0.00ns
pixel_weighted_average.exit:426  %tmp15_cast = sext i18 %tmp15 to i19

ST_4: tmp18 [1/1] 1.96ns
pixel_weighted_average.exit:427  %tmp18 = add i17 %tmp_34_2_3_cast, %tmp_34_2_2_cast

ST_4: tmp18_cast [1/1] 0.00ns
pixel_weighted_average.exit:428  %tmp18_cast = sext i17 %tmp18 to i18

ST_4: tmp17 [1/1] 2.08ns
pixel_weighted_average.exit:429  %tmp17 = add i18 %tmp_34_2_1_cast, %tmp18_cast

ST_4: tmp17_cast [1/1] 0.00ns
pixel_weighted_average.exit:430  %tmp17_cast = sext i18 %tmp17 to i19

ST_4: tmp14 [1/1] 2.08ns
pixel_weighted_average.exit:431  %tmp14 = add i19 %tmp15_cast, %tmp17_cast

ST_4: tmp14_cast [1/1] 0.00ns
pixel_weighted_average.exit:432  %tmp14_cast = sext i19 %tmp14 to i20

ST_4: tmp21 [1/1] 1.96ns
pixel_weighted_average.exit:433  %tmp21 = add i17 %tmp_34_2_6_cast, %tmp_34_2_5_cast

ST_4: tmp21_cast [1/1] 0.00ns
pixel_weighted_average.exit:434  %tmp21_cast = sext i17 %tmp21 to i18

ST_4: tmp20 [1/1] 2.08ns
pixel_weighted_average.exit:435  %tmp20 = add i18 %tmp_34_2_4_cast, %tmp21_cast

ST_4: tmp20_cast [1/1] 0.00ns
pixel_weighted_average.exit:436  %tmp20_cast = sext i18 %tmp20 to i19

ST_4: tmp23 [1/1] 1.96ns
pixel_weighted_average.exit:437  %tmp23 = add i17 %tmp_34_3_2_cast, %tmp_34_3_1_cast

ST_4: tmp23_cast [1/1] 0.00ns
pixel_weighted_average.exit:438  %tmp23_cast = sext i17 %tmp23 to i18

ST_4: tmp22 [1/1] 2.08ns
pixel_weighted_average.exit:439  %tmp22 = add i18 %tmp_34_3_cast, %tmp23_cast

ST_4: tmp22_cast [1/1] 0.00ns
pixel_weighted_average.exit:440  %tmp22_cast = sext i18 %tmp22 to i19

ST_4: tmp19 [1/1] 2.08ns
pixel_weighted_average.exit:441  %tmp19 = add i19 %tmp20_cast, %tmp22_cast

ST_4: tmp19_cast [1/1] 0.00ns
pixel_weighted_average.exit:442  %tmp19_cast = sext i19 %tmp19 to i20

ST_4: tmp13 [1/1] 2.08ns
pixel_weighted_average.exit:443  %tmp13 = add i20 %tmp14_cast, %tmp19_cast

ST_4: tmp13_cast [1/1] 0.00ns
pixel_weighted_average.exit:444  %tmp13_cast = sext i20 %tmp13 to i21

ST_4: tmp1 [1/1] 2.08ns
pixel_weighted_average.exit:445  %tmp1 = add i21 %tmp2_cast, %tmp13_cast

ST_4: tmp1_cast [1/1] 0.00ns
pixel_weighted_average.exit:446  %tmp1_cast = sext i21 %tmp1 to i22

ST_4: tmp28 [1/1] 1.96ns
pixel_weighted_average.exit:447  %tmp28 = add i17 %tmp_34_3_5_cast, %tmp_34_3_4_cast

ST_4: tmp28_cast [1/1] 0.00ns
pixel_weighted_average.exit:448  %tmp28_cast = sext i17 %tmp28 to i18

ST_4: tmp27 [1/1] 2.08ns
pixel_weighted_average.exit:449  %tmp27 = add i18 %tmp_34_3_3_cast, %tmp28_cast

ST_4: tmp27_cast [1/1] 0.00ns
pixel_weighted_average.exit:450  %tmp27_cast = sext i18 %tmp27 to i19

ST_4: tmp30 [1/1] 1.96ns
pixel_weighted_average.exit:451  %tmp30 = add i17 %tmp_34_4_1_cast, %tmp_34_4_cast

ST_4: tmp30_cast [1/1] 0.00ns
pixel_weighted_average.exit:452  %tmp30_cast = sext i17 %tmp30 to i18

ST_4: tmp29 [1/1] 2.08ns
pixel_weighted_average.exit:453  %tmp29 = add i18 %tmp_34_3_6_cast, %tmp30_cast

ST_4: tmp29_cast [1/1] 0.00ns
pixel_weighted_average.exit:454  %tmp29_cast = sext i18 %tmp29 to i19

ST_4: tmp26 [1/1] 2.08ns
pixel_weighted_average.exit:455  %tmp26 = add i19 %tmp27_cast, %tmp29_cast

ST_4: tmp26_cast [1/1] 0.00ns
pixel_weighted_average.exit:456  %tmp26_cast = sext i19 %tmp26 to i20

ST_4: tmp33 [1/1] 1.96ns
pixel_weighted_average.exit:457  %tmp33 = add i17 %tmp_34_4_4_cast, %tmp_34_4_3_cast

ST_4: tmp33_cast [1/1] 0.00ns
pixel_weighted_average.exit:458  %tmp33_cast = sext i17 %tmp33 to i18

ST_4: tmp32 [1/1] 2.08ns
pixel_weighted_average.exit:459  %tmp32 = add i18 %tmp_34_4_2_cast, %tmp33_cast

ST_4: tmp32_cast [1/1] 0.00ns
pixel_weighted_average.exit:460  %tmp32_cast = sext i18 %tmp32 to i19

ST_4: tmp35 [1/1] 1.96ns
pixel_weighted_average.exit:461  %tmp35 = add i17 %tmp_34_5_cast, %tmp_34_4_6_cast

ST_4: tmp35_cast [1/1] 0.00ns
pixel_weighted_average.exit:462  %tmp35_cast = sext i17 %tmp35 to i18

ST_4: tmp34 [1/1] 2.08ns
pixel_weighted_average.exit:463  %tmp34 = add i18 %tmp_34_4_5_cast, %tmp35_cast

ST_4: tmp34_cast [1/1] 0.00ns
pixel_weighted_average.exit:464  %tmp34_cast = sext i18 %tmp34 to i19

ST_4: tmp31 [1/1] 2.08ns
pixel_weighted_average.exit:465  %tmp31 = add i19 %tmp32_cast, %tmp34_cast

ST_4: tmp31_cast [1/1] 0.00ns
pixel_weighted_average.exit:466  %tmp31_cast = sext i19 %tmp31 to i20

ST_4: tmp25 [1/1] 2.08ns
pixel_weighted_average.exit:467  %tmp25 = add i20 %tmp26_cast, %tmp31_cast

ST_4: tmp25_cast [1/1] 0.00ns
pixel_weighted_average.exit:468  %tmp25_cast = sext i20 %tmp25 to i21

ST_4: tmp39 [1/1] 1.96ns
pixel_weighted_average.exit:469  %tmp39 = add i17 %tmp_34_5_3_cast, %tmp_34_5_2_cast

ST_4: tmp39_cast [1/1] 0.00ns
pixel_weighted_average.exit:470  %tmp39_cast = sext i17 %tmp39 to i18

ST_4: tmp38 [1/1] 2.08ns
pixel_weighted_average.exit:471  %tmp38 = add i18 %tmp_34_5_1_cast, %tmp39_cast

ST_4: tmp38_cast [1/1] 0.00ns
pixel_weighted_average.exit:472  %tmp38_cast = sext i18 %tmp38 to i19

ST_4: tmp41 [1/1] 1.96ns
pixel_weighted_average.exit:473  %tmp41 = add i17 %tmp_34_5_6_cast, %tmp_34_5_5_cast

ST_4: tmp41_cast [1/1] 0.00ns
pixel_weighted_average.exit:474  %tmp41_cast = sext i17 %tmp41 to i18

ST_4: tmp40 [1/1] 2.08ns
pixel_weighted_average.exit:475  %tmp40 = add i18 %tmp_34_5_4_cast, %tmp41_cast

ST_4: tmp40_cast [1/1] 0.00ns
pixel_weighted_average.exit:476  %tmp40_cast = sext i18 %tmp40 to i19

ST_4: tmp37 [1/1] 2.08ns
pixel_weighted_average.exit:477  %tmp37 = add i19 %tmp38_cast, %tmp40_cast

ST_4: tmp37_cast [1/1] 0.00ns
pixel_weighted_average.exit:478  %tmp37_cast = sext i19 %tmp37 to i20

ST_4: tmp44 [1/1] 1.96ns
pixel_weighted_average.exit:479  %tmp44 = add i17 %tmp_34_6_2_cast, %tmp_34_6_1_cast

ST_4: tmp44_cast [1/1] 0.00ns
pixel_weighted_average.exit:480  %tmp44_cast = sext i17 %tmp44 to i18

ST_4: tmp43 [1/1] 2.08ns
pixel_weighted_average.exit:481  %tmp43 = add i18 %tmp_34_6_cast, %tmp44_cast

ST_4: tmp43_cast [1/1] 0.00ns
pixel_weighted_average.exit:482  %tmp43_cast = sext i18 %tmp43 to i19

ST_4: tmp46 [1/1] 1.96ns
pixel_weighted_average.exit:483  %tmp46 = add i17 %tmp_34_6_4_cast, %tmp_34_6_3_cast

ST_4: tmp46_cast [1/1] 0.00ns
pixel_weighted_average.exit:484  %tmp46_cast = sext i17 %tmp46 to i18

ST_4: tmp47 [1/1] 1.96ns
pixel_weighted_average.exit:485  %tmp47 = add i17 %tmp_34_6_6_cast, %tmp_34_6_5_cast

ST_4: tmp47_cast [1/1] 0.00ns
pixel_weighted_average.exit:486  %tmp47_cast = sext i17 %tmp47 to i18

ST_4: tmp45 [1/1] 2.08ns
pixel_weighted_average.exit:487  %tmp45 = add i18 %tmp46_cast, %tmp47_cast

ST_4: tmp45_cast [1/1] 0.00ns
pixel_weighted_average.exit:488  %tmp45_cast = sext i18 %tmp45 to i19

ST_4: tmp42 [1/1] 2.08ns
pixel_weighted_average.exit:489  %tmp42 = add i19 %tmp43_cast, %tmp45_cast

ST_4: tmp42_cast [1/1] 0.00ns
pixel_weighted_average.exit:490  %tmp42_cast = sext i19 %tmp42 to i20

ST_4: tmp36 [1/1] 2.08ns
pixel_weighted_average.exit:491  %tmp36 = add i20 %tmp37_cast, %tmp42_cast

ST_4: tmp36_cast [1/1] 0.00ns
pixel_weighted_average.exit:492  %tmp36_cast = sext i20 %tmp36 to i21

ST_4: tmp24 [1/1] 2.08ns
pixel_weighted_average.exit:493  %tmp24 = add i21 %tmp25_cast, %tmp36_cast

ST_4: tmp24_cast [1/1] 0.00ns
pixel_weighted_average.exit:494  %tmp24_cast = sext i21 %tmp24 to i22

ST_4: out_temp_V_6_6 [1/1] 2.20ns
pixel_weighted_average.exit:495  %out_temp_V_6_6 = add i22 %tmp1_cast, %tmp24_cast

ST_4: tmp_24_tr [1/1] 0.00ns
pixel_weighted_average.exit:496  %tmp_24_tr = sext i22 %out_temp_V_6_6 to i23

ST_4: tmp_25_tr [1/1] 0.00ns
pixel_weighted_average.exit:497  %tmp_25_tr = sext i8 %kernel_sum_V_load to i23

ST_4: r_V [27/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 5>: 4.20ns
ST_5: r_V [26/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 6>: 4.20ns
ST_6: r_V [25/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 7>: 4.20ns
ST_7: r_V [24/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 8>: 4.20ns
ST_8: r_V [23/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 9>: 4.20ns
ST_9: r_V [22/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 10>: 4.20ns
ST_10: r_V [21/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 11>: 4.20ns
ST_11: r_V [20/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 12>: 4.20ns
ST_12: r_V [19/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 13>: 4.20ns
ST_13: r_V [18/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 14>: 4.20ns
ST_14: r_V [17/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 15>: 4.20ns
ST_15: r_V [16/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 16>: 4.20ns
ST_16: r_V [15/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 17>: 4.20ns
ST_17: r_V [14/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 18>: 4.20ns
ST_18: r_V [13/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 19>: 4.20ns
ST_19: r_V [12/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 20>: 4.20ns
ST_20: r_V [11/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 21>: 4.20ns
ST_21: r_V [10/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 22>: 4.20ns
ST_22: r_V [9/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 23>: 4.20ns
ST_23: r_V [8/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 24>: 4.20ns
ST_24: r_V [7/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 25>: 4.20ns
ST_25: r_V [6/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 26>: 4.20ns
ST_26: r_V [5/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 27>: 4.20ns
ST_27: r_V [4/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 28>: 4.20ns
ST_28: r_V [3/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 29>: 4.20ns
ST_29: r_V [2/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr


 <State 30>: 5.92ns
ST_30: tmp_14 [1/1] 0.00ns
pixel_weighted_average.exit:9  %tmp_14 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_3 [1/1] 0.00ns
pixel_weighted_average.exit:15  %empty_3 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_14)

ST_30: tmp_15 [1/1] 0.00ns
pixel_weighted_average.exit:17  %tmp_15 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_4 [1/1] 0.00ns
pixel_weighted_average.exit:23  %empty_4 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_15)

ST_30: tmp_16 [1/1] 0.00ns
pixel_weighted_average.exit:25  %tmp_16 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_5 [1/1] 0.00ns
pixel_weighted_average.exit:31  %empty_5 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_16)

ST_30: tmp_17 [1/1] 0.00ns
pixel_weighted_average.exit:33  %tmp_17 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_6 [1/1] 0.00ns
pixel_weighted_average.exit:39  %empty_6 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_17)

ST_30: tmp_18 [1/1] 0.00ns
pixel_weighted_average.exit:41  %tmp_18 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_7 [1/1] 0.00ns
pixel_weighted_average.exit:47  %empty_7 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_18)

ST_30: tmp_19 [1/1] 0.00ns
pixel_weighted_average.exit:49  %tmp_19 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_8 [1/1] 0.00ns
pixel_weighted_average.exit:55  %empty_8 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_19)

ST_30: tmp_20 [1/1] 0.00ns
pixel_weighted_average.exit:57  %tmp_20 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_9 [1/1] 0.00ns
pixel_weighted_average.exit:63  %empty_9 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_20)

ST_30: tmp_21 [1/1] 0.00ns
pixel_weighted_average.exit:65  %tmp_21 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_10 [1/1] 0.00ns
pixel_weighted_average.exit:71  %empty_10 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_21)

ST_30: tmp_22 [1/1] 0.00ns
pixel_weighted_average.exit:73  %tmp_22 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_11 [1/1] 0.00ns
pixel_weighted_average.exit:79  %empty_11 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_22)

ST_30: tmp_23 [1/1] 0.00ns
pixel_weighted_average.exit:81  %tmp_23 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_12 [1/1] 0.00ns
pixel_weighted_average.exit:87  %empty_12 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_23)

ST_30: tmp_24 [1/1] 0.00ns
pixel_weighted_average.exit:89  %tmp_24 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_13 [1/1] 0.00ns
pixel_weighted_average.exit:95  %empty_13 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_24)

ST_30: tmp_25 [1/1] 0.00ns
pixel_weighted_average.exit:97  %tmp_25 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_14 [1/1] 0.00ns
pixel_weighted_average.exit:103  %empty_14 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_25)

ST_30: tmp_26 [1/1] 0.00ns
pixel_weighted_average.exit:105  %tmp_26 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_15 [1/1] 0.00ns
pixel_weighted_average.exit:111  %empty_15 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_26)

ST_30: tmp_27 [1/1] 0.00ns
pixel_weighted_average.exit:113  %tmp_27 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_16 [1/1] 0.00ns
pixel_weighted_average.exit:119  %empty_16 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_27)

ST_30: tmp_28 [1/1] 0.00ns
pixel_weighted_average.exit:121  %tmp_28 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_17 [1/1] 0.00ns
pixel_weighted_average.exit:127  %empty_17 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_28)

ST_30: tmp_29 [1/1] 0.00ns
pixel_weighted_average.exit:129  %tmp_29 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_18 [1/1] 0.00ns
pixel_weighted_average.exit:135  %empty_18 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_29)

ST_30: tmp_30 [1/1] 0.00ns
pixel_weighted_average.exit:137  %tmp_30 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_19 [1/1] 0.00ns
pixel_weighted_average.exit:143  %empty_19 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_30)

ST_30: tmp_31 [1/1] 0.00ns
pixel_weighted_average.exit:145  %tmp_31 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_20 [1/1] 0.00ns
pixel_weighted_average.exit:151  %empty_20 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_31)

ST_30: tmp_33 [1/1] 0.00ns
pixel_weighted_average.exit:153  %tmp_33 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_21 [1/1] 0.00ns
pixel_weighted_average.exit:159  %empty_21 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_33)

ST_30: tmp_34 [1/1] 0.00ns
pixel_weighted_average.exit:161  %tmp_34 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_22 [1/1] 0.00ns
pixel_weighted_average.exit:167  %empty_22 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_34)

ST_30: tmp_35 [1/1] 0.00ns
pixel_weighted_average.exit:169  %tmp_35 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_23 [1/1] 0.00ns
pixel_weighted_average.exit:175  %empty_23 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_35)

ST_30: tmp_36 [1/1] 0.00ns
pixel_weighted_average.exit:177  %tmp_36 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_24 [1/1] 0.00ns
pixel_weighted_average.exit:183  %empty_24 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_36)

ST_30: tmp_37 [1/1] 0.00ns
pixel_weighted_average.exit:185  %tmp_37 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_25 [1/1] 0.00ns
pixel_weighted_average.exit:191  %empty_25 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_37)

ST_30: tmp_38 [1/1] 0.00ns
pixel_weighted_average.exit:193  %tmp_38 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_26 [1/1] 0.00ns
pixel_weighted_average.exit:199  %empty_26 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_38)

ST_30: tmp_39 [1/1] 0.00ns
pixel_weighted_average.exit:201  %tmp_39 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_27 [1/1] 0.00ns
pixel_weighted_average.exit:207  %empty_27 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_39)

ST_30: tmp_40 [1/1] 0.00ns
pixel_weighted_average.exit:209  %tmp_40 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_28 [1/1] 0.00ns
pixel_weighted_average.exit:215  %empty_28 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_40)

ST_30: tmp_41 [1/1] 0.00ns
pixel_weighted_average.exit:217  %tmp_41 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_29 [1/1] 0.00ns
pixel_weighted_average.exit:223  %empty_29 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_41)

ST_30: tmp_42 [1/1] 0.00ns
pixel_weighted_average.exit:225  %tmp_42 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_30 [1/1] 0.00ns
pixel_weighted_average.exit:231  %empty_30 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_42)

ST_30: tmp_43 [1/1] 0.00ns
pixel_weighted_average.exit:233  %tmp_43 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_31 [1/1] 0.00ns
pixel_weighted_average.exit:239  %empty_31 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_43)

ST_30: tmp_44 [1/1] 0.00ns
pixel_weighted_average.exit:241  %tmp_44 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_32 [1/1] 0.00ns
pixel_weighted_average.exit:247  %empty_32 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_44)

ST_30: tmp_45 [1/1] 0.00ns
pixel_weighted_average.exit:249  %tmp_45 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_33 [1/1] 0.00ns
pixel_weighted_average.exit:255  %empty_33 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_45)

ST_30: tmp_46 [1/1] 0.00ns
pixel_weighted_average.exit:257  %tmp_46 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_34 [1/1] 0.00ns
pixel_weighted_average.exit:263  %empty_34 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_46)

ST_30: tmp_47 [1/1] 0.00ns
pixel_weighted_average.exit:265  %tmp_47 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_35 [1/1] 0.00ns
pixel_weighted_average.exit:271  %empty_35 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_47)

ST_30: tmp_48 [1/1] 0.00ns
pixel_weighted_average.exit:273  %tmp_48 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_36 [1/1] 0.00ns
pixel_weighted_average.exit:279  %empty_36 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_48)

ST_30: tmp_49 [1/1] 0.00ns
pixel_weighted_average.exit:281  %tmp_49 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_37 [1/1] 0.00ns
pixel_weighted_average.exit:287  %empty_37 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_49)

ST_30: tmp_50 [1/1] 0.00ns
pixel_weighted_average.exit:289  %tmp_50 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_38 [1/1] 0.00ns
pixel_weighted_average.exit:295  %empty_38 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_50)

ST_30: tmp_51 [1/1] 0.00ns
pixel_weighted_average.exit:297  %tmp_51 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_39 [1/1] 0.00ns
pixel_weighted_average.exit:303  %empty_39 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_51)

ST_30: tmp_52 [1/1] 0.00ns
pixel_weighted_average.exit:305  %tmp_52 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_40 [1/1] 0.00ns
pixel_weighted_average.exit:311  %empty_40 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_52)

ST_30: tmp_53 [1/1] 0.00ns
pixel_weighted_average.exit:313  %tmp_53 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_41 [1/1] 0.00ns
pixel_weighted_average.exit:319  %empty_41 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_53)

ST_30: tmp_54 [1/1] 0.00ns
pixel_weighted_average.exit:321  %tmp_54 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_42 [1/1] 0.00ns
pixel_weighted_average.exit:327  %empty_42 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_54)

ST_30: tmp_55 [1/1] 0.00ns
pixel_weighted_average.exit:329  %tmp_55 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_43 [1/1] 0.00ns
pixel_weighted_average.exit:335  %empty_43 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_55)

ST_30: tmp_56 [1/1] 0.00ns
pixel_weighted_average.exit:337  %tmp_56 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_44 [1/1] 0.00ns
pixel_weighted_average.exit:343  %empty_44 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_56)

ST_30: tmp_57 [1/1] 0.00ns
pixel_weighted_average.exit:345  %tmp_57 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_45 [1/1] 0.00ns
pixel_weighted_average.exit:351  %empty_45 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_57)

ST_30: tmp_58 [1/1] 0.00ns
pixel_weighted_average.exit:353  %tmp_58 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_46 [1/1] 0.00ns
pixel_weighted_average.exit:359  %empty_46 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_58)

ST_30: tmp_59 [1/1] 0.00ns
pixel_weighted_average.exit:361  %tmp_59 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_47 [1/1] 0.00ns
pixel_weighted_average.exit:367  %empty_47 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_59)

ST_30: tmp_60 [1/1] 0.00ns
pixel_weighted_average.exit:369  %tmp_60 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_48 [1/1] 0.00ns
pixel_weighted_average.exit:375  %empty_48 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_60)

ST_30: tmp_61 [1/1] 0.00ns
pixel_weighted_average.exit:377  %tmp_61 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_49 [1/1] 0.00ns
pixel_weighted_average.exit:383  %empty_49 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_61)

ST_30: tmp_62 [1/1] 0.00ns
pixel_weighted_average.exit:385  %tmp_62 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_50 [1/1] 0.00ns
pixel_weighted_average.exit:391  %empty_50 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_62)

ST_30: tmp_63 [1/1] 0.00ns
pixel_weighted_average.exit:393  %tmp_63 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)

ST_30: empty_51 [1/1] 0.00ns
pixel_weighted_average.exit:399  %empty_51 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_63)

ST_30: r_V [1/27] 4.20ns
pixel_weighted_average.exit:498  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr

ST_30: tmp_66 [1/1] 0.00ns
pixel_weighted_average.exit:499  %tmp_66 = trunc i23 %r_V to i8

ST_30: r_V_2 [1/1] 1.72ns
pixel_weighted_average.exit:500  %r_V_2 = add i8 %kernel_off_V_load, %tmp_66

ST_30: stg_898 [1/1] 0.00ns
pixel_weighted_average.exit:501  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %out_img_V, i8 %r_V_2)

ST_30: stg_899 [1/1] 0.00ns
pixel_weighted_average.exit:502  br label %._crit_edge66


 <State 31>: 0.00ns
ST_31: stg_900 [1/1] 0.00ns
:0  ret void



============================================================
+ Verbose Summary: Timing violations
============================================================
Target clock period: 41.7ns, clock uncertainty: 5.21ns.

 No timing violations. 


============================================================
+ Verbose Summary: Binding
============================================================
N/A
* FSMD analyzer results:
  - Output states:
 - Input state : 
  - Chain level:
	State 1
	State 2
	State 3
	State 4
	State 5
	State 6
	State 7
	State 8
	State 9
	State 10
	State 11
	State 12
	State 13
	State 14
	State 15
	State 16
	State 17
	State 18
	State 19
	State 20
	State 21
	State 22
	State 23
	State 24
	State 25
	State 26
	State 27
	State 28
	State 29
	State 30
	State 31


============================================================
+ Verbose Summary: Datapath Resource usage 
============================================================
N/A
