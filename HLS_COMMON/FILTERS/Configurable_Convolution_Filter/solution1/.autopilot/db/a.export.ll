; ModuleID = 'C:/Users/Luca/Desktop/ProgettoVivado/OV_7670/HLS_COMMON/FILTERS/Configurable_Convolution_Filter/solution1/.autopilot/db/a.o.2.bc'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-w64-mingw32"

@window_V_6_6 = internal unnamed_addr global i8 0
@window_V_6_5 = internal unnamed_addr global i8 0
@window_V_6_4 = internal unnamed_addr global i8 0
@window_V_6_3 = internal unnamed_addr global i8 0
@window_V_6_2 = internal unnamed_addr global i8 0
@window_V_6_1 = internal unnamed_addr global i8 0
@window_V_5_6 = internal unnamed_addr global i8 0
@window_V_5_5 = internal unnamed_addr global i8 0
@window_V_5_4 = internal unnamed_addr global i8 0
@window_V_5_3 = internal unnamed_addr global i8 0
@window_V_5_2 = internal unnamed_addr global i8 0
@window_V_5_1 = internal unnamed_addr global i8 0
@window_V_4_6 = internal unnamed_addr global i8 0
@window_V_4_5 = internal unnamed_addr global i8 0
@window_V_4_4 = internal unnamed_addr global i8 0
@window_V_4_3 = internal unnamed_addr global i8 0
@window_V_4_2 = internal unnamed_addr global i8 0
@window_V_4_1 = internal unnamed_addr global i8 0
@window_V_3_6 = internal unnamed_addr global i8 0
@window_V_3_5 = internal unnamed_addr global i8 0
@window_V_3_4 = internal unnamed_addr global i8 0
@window_V_3_3 = internal unnamed_addr global i8 0
@window_V_3_2 = internal unnamed_addr global i8 0
@window_V_3_1 = internal unnamed_addr global i8 0
@window_V_2_6 = internal unnamed_addr global i8 0
@window_V_2_5 = internal unnamed_addr global i8 0
@window_V_2_4 = internal unnamed_addr global i8 0
@window_V_2_3 = internal unnamed_addr global i8 0
@window_V_2_2 = internal unnamed_addr global i8 0
@window_V_2_1 = internal unnamed_addr global i8 0
@window_V_1_6 = internal unnamed_addr global i8 0
@window_V_1_5 = internal unnamed_addr global i8 0
@window_V_1_4 = internal unnamed_addr global i8 0
@window_V_1_3 = internal unnamed_addr global i8 0
@window_V_1_2 = internal unnamed_addr global i8 0
@window_V_1_1 = internal unnamed_addr global i8 0
@window_V_0_6 = internal unnamed_addr global i8 0
@window_V_0_5 = internal unnamed_addr global i8 0
@window_V_0_4 = internal unnamed_addr global i8 0
@window_V_0_3 = internal unnamed_addr global i8 0
@window_V_0_2 = internal unnamed_addr global i8 0
@window_V_0_1 = internal unnamed_addr global i8 0
@llvm_global_ctors_1 = appending global [1 x void ()*] [void ()* @_GLOBAL__I_a]
@llvm_global_ctors_0 = appending global [1 x i32] [i32 65535]
@line_buffer_V_5 = internal unnamed_addr global [640 x i8] zeroinitializer
@line_buffer_V_4 = internal unnamed_addr global [640 x i8] zeroinitializer
@line_buffer_V_3 = internal unnamed_addr global [640 x i8] zeroinitializer
@line_buffer_V_2 = internal unnamed_addr global [640 x i8] zeroinitializer
@line_buffer_V_1 = internal unnamed_addr global [640 x i8] zeroinitializer
@line_buffer_V_0 = internal unnamed_addr global [640 x i8] zeroinitializer
@kernel_sum_V = internal unnamed_addr global i8 1
@kernel_off_V = internal unnamed_addr global i8 0
@kernel_V_6_6 = internal unnamed_addr global i8 0
@kernel_V_6_5 = internal unnamed_addr global i8 0
@kernel_V_6_4 = internal unnamed_addr global i8 0
@kernel_V_6_3 = internal unnamed_addr global i8 0
@kernel_V_6_2 = internal unnamed_addr global i8 0
@kernel_V_6_1 = internal unnamed_addr global i8 0
@kernel_V_6_0 = internal unnamed_addr global i8 0
@kernel_V_5_6 = internal unnamed_addr global i8 0
@kernel_V_5_5 = internal unnamed_addr global i8 0
@kernel_V_5_4 = internal unnamed_addr global i8 0
@kernel_V_5_3 = internal unnamed_addr global i8 0
@kernel_V_5_2 = internal unnamed_addr global i8 0
@kernel_V_5_1 = internal unnamed_addr global i8 0
@kernel_V_5_0 = internal unnamed_addr global i8 0
@kernel_V_4_6 = internal unnamed_addr global i8 0
@kernel_V_4_5 = internal unnamed_addr global i8 0
@kernel_V_4_4 = internal unnamed_addr global i8 0
@kernel_V_4_3 = internal unnamed_addr global i8 0
@kernel_V_4_2 = internal unnamed_addr global i8 0
@kernel_V_4_1 = internal unnamed_addr global i8 0
@kernel_V_4_0 = internal unnamed_addr global i8 0
@kernel_V_3_6 = internal unnamed_addr global i8 0
@kernel_V_3_5 = internal unnamed_addr global i8 0
@kernel_V_3_4 = internal unnamed_addr global i8 0
@kernel_V_3_3 = internal unnamed_addr global i8 0
@kernel_V_3_2 = internal unnamed_addr global i8 0
@kernel_V_3_1 = internal unnamed_addr global i8 0
@kernel_V_3_0 = internal unnamed_addr global i8 0
@kernel_V_2_6 = internal unnamed_addr global i8 0
@kernel_V_2_5 = internal unnamed_addr global i8 0
@kernel_V_2_4 = internal unnamed_addr global i8 0
@kernel_V_2_3 = internal unnamed_addr global i8 0
@kernel_V_2_2 = internal unnamed_addr global i8 0
@kernel_V_2_1 = internal unnamed_addr global i8 0
@kernel_V_2_0 = internal unnamed_addr global i8 0
@kernel_V_1_6 = internal unnamed_addr global i8 0
@kernel_V_1_5 = internal unnamed_addr global i8 0
@kernel_V_1_4 = internal unnamed_addr global i8 0
@kernel_V_1_3 = internal unnamed_addr global i8 0
@kernel_V_1_2 = internal unnamed_addr global i8 0
@kernel_V_1_1 = internal unnamed_addr global i8 0
@kernel_V_1_0 = internal unnamed_addr global i8 0
@kernel_V_0_6 = internal unnamed_addr global i8 0
@kernel_V_0_5 = internal unnamed_addr global i8 0
@kernel_V_0_4 = internal unnamed_addr global i8 0
@kernel_V_0_3 = internal unnamed_addr global i8 0
@kernel_V_0_2 = internal unnamed_addr global i8 0
@kernel_V_0_1 = internal unnamed_addr global i8 0
@kernel_V_0_0 = internal unnamed_addr global i8 0
@convolution_filter_str = internal unnamed_addr constant [19 x i8] c"convolution_filter\00"
@RAM_1P_str = internal unnamed_addr constant [7 x i8] c"RAM_1P\00"
@Loop_row_Loop_col_str = internal unnamed_addr constant [18 x i8] c"Loop_row_Loop_col\00"
@p_str7 = private unnamed_addr constant [5 x i8] c"axis\00", align 1
@p_str6 = private unnamed_addr constant [10 x i8] c"s_axilite\00", align 1
@p_str5 = private unnamed_addr constant [8 x i8] c"Mul_LUT\00", align 1
@p_str4 = private unnamed_addr constant [29 x i8] c"?Mul_LUT_temp_Region_2196959\00", align 1
@p_str10 = private unnamed_addr constant [9 x i8] c"Loop_col\00", align 1
@p_str = private unnamed_addr constant [1 x i8] zeroinitializer, align 1

declare void @llvm.dbg.value(metadata, i64, metadata) nounwind readnone

declare void @llvm.dbg.declare(metadata, metadata) nounwind readnone

define void @convolution_filter([51 x i8]* %kernel_config_V, i8* %in_img_V, i8* %out_img_V) {
.preheader51.preheader:
  %convolution_filter_ap_int_ap_2 = alloca i32
  %convolution_filter_ap_int_ap_1 = alloca i32
  %in_temp_V_1 = alloca i8
  %window_V_5_6_loc_1 = alloca i8
  %window_V_4_6_loc_1 = alloca i8
  %window_V_3_6_loc_1 = alloca i8
  %window_V_2_6_loc_1 = alloca i8
  %window_V_1_6_loc_1 = alloca i8
  %window_V_0_6_loc_1 = alloca i8
  call void (...)* @_ssdm_op_SpecBitsMap([51 x i8]* %kernel_config_V), !map !7
  call void (...)* @_ssdm_op_SpecBitsMap(i8* %in_img_V), !map !13
  call void (...)* @_ssdm_op_SpecBitsMap(i8* %out_img_V), !map !19
  call void (...)* @_ssdm_op_SpecTopModule([19 x i8]* @convolution_filter_str) nounwind
  %empty = call i32 (...)* @_ssdm_op_SpecMemCore([51 x i8]* %kernel_config_V, [1 x i8]* @p_str, [7 x i8]* @RAM_1P_str, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  call void (...)* @_ssdm_op_SpecInterface([51 x i8]* %kernel_config_V, [10 x i8]* @p_str6, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str) nounwind
  call void (...)* @_ssdm_op_SpecInterface(i8* %out_img_V, [5 x i8]* @p_str7, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str)
  call void (...)* @_ssdm_op_SpecInterface(i8* %in_img_V, [5 x i8]* @p_str7, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str)
  %kernel_config_V_addr = getelementptr [51 x i8]* %kernel_config_V, i64 0, i64 49
  %kernel_config_V_addr_1 = getelementptr [51 x i8]* %kernel_config_V, i64 0, i64 50
  %window_V_0_6_load = load i8* @window_V_0_6, align 1
  %window_V_1_6_load = load i8* @window_V_1_6, align 1
  %window_V_2_6_load = load i8* @window_V_2_6, align 1
  %window_V_3_6_load = load i8* @window_V_3_6, align 1
  %window_V_4_6_load = load i8* @window_V_4_6, align 1
  %window_V_5_6_load = load i8* @window_V_5_6, align 1
  %window_V_6_6_load = load i8* @window_V_6_6, align 1
  store i8 %window_V_0_6_load, i8* %window_V_0_6_loc_1
  store i8 %window_V_1_6_load, i8* %window_V_1_6_loc_1
  store i8 %window_V_2_6_load, i8* %window_V_2_6_loc_1
  store i8 %window_V_3_6_load, i8* %window_V_3_6_loc_1
  store i8 %window_V_4_6_load, i8* %window_V_4_6_loc_1
  store i8 %window_V_5_6_load, i8* %window_V_5_6_loc_1
  store i8 %window_V_6_6_load, i8* %in_temp_V_1
  store i32 0, i32* %convolution_filter_ap_int_ap_1
  store i32 0, i32* %convolution_filter_ap_int_ap_2
  br label %0

; <label>:0                                       ; preds = %.preheader51.preheader, %._crit_edge66
  %indvar_flatten = phi i19 [ 0, %.preheader51.preheader ], [ %indvar_flatten_next, %._crit_edge66 ]
  %convolution_mulfilter_ap_int_ap = phi i19 [ 0, %.preheader51.preheader ], [ %convolution_filter_ap_int_ap_7, %._crit_edge66 ]
  %row = phi i9 [ 0, %.preheader51.preheader ], [ %row_mid2, %._crit_edge66 ]
  %convolution_filter_ap_int_ap_3 = phi i19 [ 0, %.preheader51.preheader ], [ %tmp_32, %._crit_edge66 ]
  %col = phi i10 [ 0, %.preheader51.preheader ], [ %col_1, %._crit_edge66 ]
  %in_temp_V_1_load = load i8* %in_temp_V_1
  %window_V_5_6_loc_1_load = load i8* %window_V_5_6_loc_1
  %window_V_4_6_loc_1_load = load i8* %window_V_4_6_loc_1
  %window_V_3_6_loc_1_load = load i8* %window_V_3_6_loc_1
  %window_V_2_6_loc_1_load = load i8* %window_V_2_6_loc_1
  %window_V_1_6_loc_1_load = load i8* %window_V_1_6_loc_1
  %window_V_0_6_loc_1_load = load i8* %window_V_0_6_loc_1
  %exitcond_flatten = icmp eq i19 %indvar_flatten, -213719
  %indvar_flatten_next = add i19 %indvar_flatten, 1
  br i1 %exitcond_flatten, label %7, label %.reset

._crit_edge63:                                    ; preds = %.reset
  %convolution_filter_ap_int_ap_4 = load i32* %convolution_filter_ap_int_ap_2
  %convolution_filter_ap_int_ap_5 = load i32* %convolution_filter_ap_int_ap_1
  %tmp_5 = icmp sgt i32 %convolution_filter_ap_int_ap_4, 6
  %tmp_7 = add nsw i32 1, %convolution_filter_ap_int_ap_5
  %sel_SEBB = select i1 %tmp_5, i32 %tmp_7, i32 %convolution_filter_ap_int_ap_5
  %sel_SEBB1 = select i1 %tmp_5, i32 0, i32 %convolution_filter_ap_int_ap_4
  %tmp_s = zext i19 %convolution_filter_ap_int_ap_6 to i64
  %kernel_config_V_addr_2 = getelementptr [51 x i8]* %kernel_config_V, i64 0, i64 %tmp_s
  %kernel_config_V_load = load i8* %kernel_config_V_addr_2, align 1
  %tmp_64 = trunc i32 %sel_SEBB to i3
  %tmp_65 = trunc i32 %sel_SEBB1 to i3
  switch i3 %tmp_64, label %branch6 [
    i3 0, label %branch0
    i3 1, label %branch1
    i3 2, label %branch2
    i3 3, label %branch3
    i3 -4, label %branch4
    i3 -3, label %branch5
  ]

._crit_edge6376:                                  ; preds = %branch6138, %branch5129, %branch4120, %branch3111, %branch2102, %branch193, %branch084
  %tmp_3 = add nsw i32 %sel_SEBB1, 1
  store i32 %sel_SEBB, i32* %convolution_filter_ap_int_ap_1
  store i32 %tmp_3, i32* %convolution_filter_ap_int_ap_2
  br label %.preheader45.preheader.0

; <label>:1                                       ; preds = %.reset
  %tmp_6 = icmp eq i19 %convolution_filter_ap_int_ap_6, 49
  br i1 %tmp_6, label %2, label %3

; <label>:2                                       ; preds = %1
  %kernel_config_V_load_1 = load i8* %kernel_config_V_addr, align 1
  store i8 %kernel_config_V_load_1, i8* @kernel_sum_V, align 1
  br label %5

; <label>:3                                       ; preds = %1
  %tmp_8 = icmp eq i19 %convolution_filter_ap_int_ap_6, 50
  br i1 %tmp_8, label %4, label %._crit_edge64

; <label>:4                                       ; preds = %3
  %kernel_config_V_load_2 = load i8* %kernel_config_V_addr_1, align 1
  store i8 %kernel_config_V_load_2, i8* @kernel_off_V, align 1
  br label %._crit_edge64

._crit_edge64:                                    ; preds = %4, %3
  br label %5

; <label>:5                                       ; preds = %._crit_edge64, %2
  br label %.preheader45.preheader.0

.preheader45.preheader.0:                         ; preds = %5, %._crit_edge6376
  %window_V_0_1_load = load i8* @window_V_0_1, align 1
  %window_V_0_2_load = load i8* @window_V_0_2, align 2
  store i8 %window_V_0_2_load, i8* @window_V_0_1, align 1
  %window_V_0_3_load = load i8* @window_V_0_3, align 1
  store i8 %window_V_0_3_load, i8* @window_V_0_2, align 2
  %window_V_0_4_load = load i8* @window_V_0_4, align 4
  store i8 %window_V_0_4_load, i8* @window_V_0_3, align 1
  %window_V_0_5_load = load i8* @window_V_0_5, align 1
  store i8 %window_V_0_5_load, i8* @window_V_0_4, align 4
  store i8 %window_V_0_6_loc_1_load, i8* @window_V_0_5, align 1
  %window_V_1_1_load = load i8* @window_V_1_1, align 1
  %window_V_1_2_load = load i8* @window_V_1_2, align 1
  store i8 %window_V_1_2_load, i8* @window_V_1_1, align 1
  %window_V_1_3_load = load i8* @window_V_1_3, align 1
  store i8 %window_V_1_3_load, i8* @window_V_1_2, align 1
  %window_V_1_4_load = load i8* @window_V_1_4, align 1
  store i8 %window_V_1_4_load, i8* @window_V_1_3, align 1
  %window_V_1_5_load = load i8* @window_V_1_5, align 1
  store i8 %window_V_1_5_load, i8* @window_V_1_4, align 1
  store i8 %window_V_1_6_loc_1_load, i8* @window_V_1_5, align 1
  %window_V_2_1_load = load i8* @window_V_2_1, align 1
  %window_V_2_2_load = load i8* @window_V_2_2, align 2
  store i8 %window_V_2_2_load, i8* @window_V_2_1, align 1
  %window_V_2_3_load = load i8* @window_V_2_3, align 1
  store i8 %window_V_2_3_load, i8* @window_V_2_2, align 2
  %window_V_2_4_load = load i8* @window_V_2_4, align 2
  store i8 %window_V_2_4_load, i8* @window_V_2_3, align 1
  %window_V_2_5_load = load i8* @window_V_2_5, align 1
  store i8 %window_V_2_5_load, i8* @window_V_2_4, align 2
  store i8 %window_V_2_6_loc_1_load, i8* @window_V_2_5, align 1
  %window_V_3_1_load = load i8* @window_V_3_1, align 1
  %window_V_3_2_load = load i8* @window_V_3_2, align 1
  store i8 %window_V_3_2_load, i8* @window_V_3_1, align 1
  %window_V_3_3_load = load i8* @window_V_3_3, align 1
  store i8 %window_V_3_3_load, i8* @window_V_3_2, align 1
  %window_V_3_4_load = load i8* @window_V_3_4, align 1
  store i8 %window_V_3_4_load, i8* @window_V_3_3, align 1
  %window_V_3_5_load = load i8* @window_V_3_5, align 1
  store i8 %window_V_3_5_load, i8* @window_V_3_4, align 1
  store i8 %window_V_3_6_loc_1_load, i8* @window_V_3_5, align 1
  %window_V_4_1_load = load i8* @window_V_4_1, align 1
  %window_V_4_2_load = load i8* @window_V_4_2, align 2
  store i8 %window_V_4_2_load, i8* @window_V_4_1, align 1
  %window_V_4_3_load = load i8* @window_V_4_3, align 1
  store i8 %window_V_4_3_load, i8* @window_V_4_2, align 2
  %window_V_4_4_load = load i8* @window_V_4_4, align 4
  store i8 %window_V_4_4_load, i8* @window_V_4_3, align 1
  %window_V_4_5_load = load i8* @window_V_4_5, align 1
  store i8 %window_V_4_5_load, i8* @window_V_4_4, align 4
  store i8 %window_V_4_6_loc_1_load, i8* @window_V_4_5, align 1
  %window_V_5_1_load = load i8* @window_V_5_1, align 1
  %window_V_5_2_load = load i8* @window_V_5_2, align 1
  store i8 %window_V_5_2_load, i8* @window_V_5_1, align 1
  %window_V_5_3_load = load i8* @window_V_5_3, align 1
  store i8 %window_V_5_3_load, i8* @window_V_5_2, align 1
  %window_V_5_4_load = load i8* @window_V_5_4, align 1
  store i8 %window_V_5_4_load, i8* @window_V_5_3, align 1
  %window_V_5_5_load = load i8* @window_V_5_5, align 1
  store i8 %window_V_5_5_load, i8* @window_V_5_4, align 1
  store i8 %window_V_5_6_loc_1_load, i8* @window_V_5_5, align 1
  %window_V_6_1_load = load i8* @window_V_6_1, align 1
  %window_V_6_2_load = load i8* @window_V_6_2, align 2
  store i8 %window_V_6_2_load, i8* @window_V_6_1, align 1
  %window_V_6_3_load = load i8* @window_V_6_3, align 1
  store i8 %window_V_6_3_load, i8* @window_V_6_2, align 2
  %window_V_6_4_load = load i8* @window_V_6_4, align 2
  store i8 %window_V_6_4_load, i8* @window_V_6_3, align 1
  %window_V_6_5_load = load i8* @window_V_6_5, align 1
  store i8 %window_V_6_5_load, i8* @window_V_6_4, align 2
  store i8 %in_temp_V_1_load, i8* @window_V_6_5, align 1
  %tmp_10 = icmp ult i10 %col_mid2, -384
  br i1 %tmp_10, label %.preheader.preheader, label %.loopexit

.preheader.preheader:                             ; preds = %.preheader45.preheader.0
  %tmp_11 = zext i10 %col_mid2 to i64
  %line_buffer_V_0_addr = getelementptr [640 x i8]* @line_buffer_V_0, i64 0, i64 %tmp_11
  %line_buffer_V_0_load = load i8* %line_buffer_V_0_addr, align 1
  store i8 %line_buffer_V_0_load, i8* @window_V_0_6, align 2
  %line_buffer_V_1_addr = getelementptr [640 x i8]* @line_buffer_V_1, i64 0, i64 %tmp_11
  %line_buffer_V_1_load = load i8* %line_buffer_V_1_addr, align 1
  store i8 %line_buffer_V_1_load, i8* %line_buffer_V_0_addr, align 1
  store i8 %line_buffer_V_1_load, i8* @window_V_1_6, align 1
  %line_buffer_V_2_addr = getelementptr [640 x i8]* @line_buffer_V_2, i64 0, i64 %tmp_11
  %line_buffer_V_2_load = load i8* %line_buffer_V_2_addr, align 1
  store i8 %line_buffer_V_2_load, i8* %line_buffer_V_1_addr, align 1
  store i8 %line_buffer_V_2_load, i8* @window_V_2_6, align 2
  %line_buffer_V_3_addr = getelementptr [640 x i8]* @line_buffer_V_3, i64 0, i64 %tmp_11
  %line_buffer_V_3_load = load i8* %line_buffer_V_3_addr, align 1
  store i8 %line_buffer_V_3_load, i8* %line_buffer_V_2_addr, align 1
  store i8 %line_buffer_V_3_load, i8* @window_V_3_6, align 1
  %line_buffer_V_4_addr = getelementptr [640 x i8]* @line_buffer_V_4, i64 0, i64 %tmp_11
  %line_buffer_V_4_load = load i8* %line_buffer_V_4_addr, align 1
  store i8 %line_buffer_V_4_load, i8* %line_buffer_V_3_addr, align 1
  store i8 %line_buffer_V_4_load, i8* @window_V_4_6, align 2
  %line_buffer_V_5_addr = getelementptr [640 x i8]* @line_buffer_V_5, i64 0, i64 %tmp_11
  %line_buffer_V_5_load = load i8* %line_buffer_V_5_addr, align 1
  store i8 %line_buffer_V_5_load, i8* %line_buffer_V_4_addr, align 1
  store i8 %line_buffer_V_5_load, i8* @window_V_5_6, align 1
  store i8 %line_buffer_V_0_load, i8* %window_V_0_6_loc_1
  store i8 %line_buffer_V_1_load, i8* %window_V_1_6_loc_1
  store i8 %line_buffer_V_2_load, i8* %window_V_2_6_loc_1
  store i8 %line_buffer_V_3_load, i8* %window_V_3_6_loc_1
  store i8 %line_buffer_V_4_load, i8* %window_V_4_6_loc_1
  store i8 %line_buffer_V_5_load, i8* %window_V_5_6_loc_1
  br label %.loopexit

.loopexit:                                        ; preds = %.preheader.preheader, %.preheader45.preheader.0
  %or_cond = and i1 %tmp_10, %tmp_mid2
  br i1 %or_cond, label %6, label %.loopexit._crit_edge

; <label>:6                                       ; preds = %.loopexit
  %in_temp_V = call i8 @_ssdm_op_Read.axis.volatile.i8P(i8* %in_img_V)
  store i8 %in_temp_V, i8* @window_V_6_6, align 2
  %tmp_12 = zext i10 %col_mid2 to i64
  %line_buffer_V_5_addr_1 = getelementptr [640 x i8]* @line_buffer_V_5, i64 0, i64 %tmp_12
  store i8 %in_temp_V, i8* %line_buffer_V_5_addr_1, align 1
  store i8 %in_temp_V, i8* %in_temp_V_1
  br label %.loopexit._crit_edge

.loopexit._crit_edge:                             ; preds = %6, %.loopexit
  %tmp_13 = icmp ugt i10 %col_mid2, 2
  %or_cond1 = and i1 %tmp_2_mid2, %tmp_13
  br i1 %or_cond1, label %pixel_weighted_average.exit, label %._crit_edge66

pixel_weighted_average.exit:                      ; preds = %.loopexit._crit_edge
  %in_temp_V_1_load_1 = load i8* %in_temp_V_1
  %window_V_5_6_loc_1_load_1 = load i8* %window_V_5_6_loc_1
  %window_V_4_6_loc_1_load_1 = load i8* %window_V_4_6_loc_1
  %window_V_3_6_loc_1_load_1 = load i8* %window_V_3_6_loc_1
  %window_V_2_6_loc_1_load_1 = load i8* %window_V_2_6_loc_1
  %window_V_1_6_loc_1_load_1 = load i8* %window_V_1_6_loc_1
  %window_V_0_6_loc_1_load_1 = load i8* %window_V_0_6_loc_1
  %kernel_sum_V_load = load i8* @kernel_sum_V, align 1
  %kernel_off_V_load = load i8* @kernel_off_V, align 1
  %tmp_14 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1 = zext i8 %window_V_0_1_load to i16
  %kernel_V_0_0_load = load i8* @kernel_V_0_0, align 16
  %rhs_V_1 = sext i8 %kernel_V_0_0_load to i16
  %r_V_s = mul i16 %rhs_V_1, %lhs_V_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_s, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_3 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_14)
  %tmp_341_cast = sext i16 %r_V_s to i18
  %tmp_15 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_0_1 = zext i8 %window_V_0_2_load to i16
  %kernel_V_0_1_load = load i8* @kernel_V_0_1, align 1
  %rhs_V_1_0_1 = sext i8 %kernel_V_0_1_load to i16
  %r_V_2_0_1 = mul i16 %rhs_V_1_0_1, %lhs_V_1_0_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_4 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_15)
  %tmp_34_0_1_cast = sext i16 %r_V_2_0_1 to i17
  %tmp_16 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_0_2 = zext i8 %window_V_0_3_load to i16
  %kernel_V_0_2_load = load i8* @kernel_V_0_2, align 2
  %rhs_V_1_0_2 = sext i8 %kernel_V_0_2_load to i16
  %r_V_2_0_2 = mul i16 %rhs_V_1_0_2, %lhs_V_1_0_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_5 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_16)
  %tmp_34_0_2_cast = sext i16 %r_V_2_0_2 to i17
  %tmp_17 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_0_3 = zext i8 %window_V_0_4_load to i16
  %kernel_V_0_3_load = load i8* @kernel_V_0_3, align 1
  %rhs_V_1_0_3 = sext i8 %kernel_V_0_3_load to i16
  %r_V_2_0_3 = mul i16 %rhs_V_1_0_3, %lhs_V_1_0_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_6 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_17)
  %tmp_34_0_3_cast = sext i16 %r_V_2_0_3 to i18
  %tmp_18 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_0_4 = zext i8 %window_V_0_5_load to i16
  %kernel_V_0_4_load = load i8* @kernel_V_0_4, align 4
  %rhs_V_1_0_4 = sext i8 %kernel_V_0_4_load to i16
  %r_V_2_0_4 = mul i16 %rhs_V_1_0_4, %lhs_V_1_0_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_7 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_18)
  %tmp_34_0_4_cast = sext i16 %r_V_2_0_4 to i17
  %tmp_19 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_0_5 = zext i8 %window_V_0_6_loc_1_load to i16
  %kernel_V_0_5_load = load i8* @kernel_V_0_5, align 1
  %rhs_V_1_0_5 = sext i8 %kernel_V_0_5_load to i16
  %r_V_2_0_5 = mul i16 %rhs_V_1_0_5, %lhs_V_1_0_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_8 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_19)
  %tmp_34_0_5_cast = sext i16 %r_V_2_0_5 to i17
  %tmp_20 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_0_6 = zext i8 %window_V_0_6_loc_1_load_1 to i16
  %kernel_V_0_6_load = load i8* @kernel_V_0_6, align 2
  %rhs_V_1_0_6 = sext i8 %kernel_V_0_6_load to i16
  %r_V_2_0_6 = mul i16 %rhs_V_1_0_6, %lhs_V_1_0_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_0_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_9 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_20)
  %tmp_34_0_6_cast = sext i16 %r_V_2_0_6 to i18
  %tmp_21 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1 = zext i8 %window_V_1_1_load to i16
  %kernel_V_1_0_load = load i8* @kernel_V_1_0, align 1
  %rhs_V_1_1 = sext i8 %kernel_V_1_0_load to i16
  %r_V_2_1 = mul i16 %rhs_V_1_1, %lhs_V_1_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_10 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_21)
  %tmp_34_1_cast = sext i16 %r_V_2_1 to i17
  %tmp_22 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1_1 = zext i8 %window_V_1_2_load to i16
  %kernel_V_1_1_load = load i8* @kernel_V_1_1, align 1
  %rhs_V_1_1_1 = sext i8 %kernel_V_1_1_load to i16
  %r_V_2_1_1 = mul i16 %rhs_V_1_1_1, %lhs_V_1_1_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_11 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_22)
  %tmp_34_1_1_cast = sext i16 %r_V_2_1_1 to i17
  %tmp_23 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1_2 = zext i8 %window_V_1_3_load to i16
  %kernel_V_1_2_load = load i8* @kernel_V_1_2, align 1
  %rhs_V_1_1_2 = sext i8 %kernel_V_1_2_load to i16
  %r_V_2_1_2 = mul i16 %rhs_V_1_1_2, %lhs_V_1_1_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_12 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_23)
  %tmp_34_1_2_cast = sext i16 %r_V_2_1_2 to i18
  %tmp_24 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1_3 = zext i8 %window_V_1_4_load to i16
  %kernel_V_1_3_load = load i8* @kernel_V_1_3, align 1
  %rhs_V_1_1_3 = sext i8 %kernel_V_1_3_load to i16
  %r_V_2_1_3 = mul i16 %rhs_V_1_1_3, %lhs_V_1_1_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_13 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_24)
  %tmp_34_1_3_cast = sext i16 %r_V_2_1_3 to i17
  %tmp_25 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1_4 = zext i8 %window_V_1_5_load to i16
  %kernel_V_1_4_load = load i8* @kernel_V_1_4, align 1
  %rhs_V_1_1_4 = sext i8 %kernel_V_1_4_load to i16
  %r_V_2_1_4 = mul i16 %rhs_V_1_1_4, %lhs_V_1_1_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_14 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_25)
  %tmp_34_1_4_cast = sext i16 %r_V_2_1_4 to i17
  %tmp_26 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1_5 = zext i8 %window_V_1_6_loc_1_load to i16
  %kernel_V_1_5_load = load i8* @kernel_V_1_5, align 1
  %rhs_V_1_1_5 = sext i8 %kernel_V_1_5_load to i16
  %r_V_2_1_5 = mul i16 %rhs_V_1_1_5, %lhs_V_1_1_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_15 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_26)
  %tmp_34_1_5_cast = sext i16 %r_V_2_1_5 to i18
  %tmp_27 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_1_6 = zext i8 %window_V_1_6_loc_1_load_1 to i16
  %kernel_V_1_6_load = load i8* @kernel_V_1_6, align 1
  %rhs_V_1_1_6 = sext i8 %kernel_V_1_6_load to i16
  %r_V_2_1_6 = mul i16 %rhs_V_1_1_6, %lhs_V_1_1_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_1_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_16 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_27)
  %tmp_34_1_6_cast = sext i16 %r_V_2_1_6 to i17
  %tmp_28 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2 = zext i8 %window_V_2_1_load to i16
  %kernel_V_2_0_load = load i8* @kernel_V_2_0, align 2
  %rhs_V_1_2 = sext i8 %kernel_V_2_0_load to i16
  %r_V_2_2 = mul i16 %rhs_V_1_2, %lhs_V_1_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_17 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_28)
  %tmp_34_2_cast = sext i16 %r_V_2_2 to i17
  %tmp_29 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2_1 = zext i8 %window_V_2_2_load to i16
  %kernel_V_2_1_load = load i8* @kernel_V_2_1, align 1
  %rhs_V_1_2_1 = sext i8 %kernel_V_2_1_load to i16
  %r_V_2_2_1 = mul i16 %rhs_V_1_2_1, %lhs_V_1_2_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_18 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_29)
  %tmp_34_2_1_cast = sext i16 %r_V_2_2_1 to i18
  %tmp_30 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2_2 = zext i8 %window_V_2_3_load to i16
  %kernel_V_2_2_load = load i8* @kernel_V_2_2, align 2
  %rhs_V_1_2_2 = sext i8 %kernel_V_2_2_load to i16
  %r_V_2_2_2 = mul i16 %rhs_V_1_2_2, %lhs_V_1_2_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_19 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_30)
  %tmp_34_2_2_cast = sext i16 %r_V_2_2_2 to i17
  %tmp_31 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2_3 = zext i8 %window_V_2_4_load to i16
  %kernel_V_2_3_load = load i8* @kernel_V_2_3, align 1
  %rhs_V_1_2_3 = sext i8 %kernel_V_2_3_load to i16
  %r_V_2_2_3 = mul i16 %rhs_V_1_2_3, %lhs_V_1_2_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_20 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_31)
  %tmp_34_2_3_cast = sext i16 %r_V_2_2_3 to i17
  %tmp_33 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2_4 = zext i8 %window_V_2_5_load to i16
  %kernel_V_2_4_load = load i8* @kernel_V_2_4, align 2
  %rhs_V_1_2_4 = sext i8 %kernel_V_2_4_load to i16
  %r_V_2_2_4 = mul i16 %rhs_V_1_2_4, %lhs_V_1_2_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_21 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_33)
  %tmp_34_2_4_cast = sext i16 %r_V_2_2_4 to i18
  %tmp_34 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2_5 = zext i8 %window_V_2_6_loc_1_load to i16
  %kernel_V_2_5_load = load i8* @kernel_V_2_5, align 1
  %rhs_V_1_2_5 = sext i8 %kernel_V_2_5_load to i16
  %r_V_2_2_5 = mul i16 %rhs_V_1_2_5, %lhs_V_1_2_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_22 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_34)
  %tmp_34_2_5_cast = sext i16 %r_V_2_2_5 to i17
  %tmp_35 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_2_6 = zext i8 %window_V_2_6_loc_1_load_1 to i16
  %kernel_V_2_6_load = load i8* @kernel_V_2_6, align 2
  %rhs_V_1_2_6 = sext i8 %kernel_V_2_6_load to i16
  %r_V_2_2_6 = mul i16 %rhs_V_1_2_6, %lhs_V_1_2_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_2_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_23 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_35)
  %tmp_34_2_6_cast = sext i16 %r_V_2_2_6 to i17
  %tmp_36 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3 = zext i8 %window_V_3_1_load to i16
  %kernel_V_3_0_load = load i8* @kernel_V_3_0, align 1
  %rhs_V_1_3 = sext i8 %kernel_V_3_0_load to i16
  %r_V_2_3 = mul i16 %rhs_V_1_3, %lhs_V_1_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_24 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_36)
  %tmp_34_3_cast = sext i16 %r_V_2_3 to i18
  %tmp_37 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3_1 = zext i8 %window_V_3_2_load to i16
  %kernel_V_3_1_load = load i8* @kernel_V_3_1, align 1
  %rhs_V_1_3_1 = sext i8 %kernel_V_3_1_load to i16
  %r_V_2_3_1 = mul i16 %rhs_V_1_3_1, %lhs_V_1_3_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_25 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_37)
  %tmp_34_3_1_cast = sext i16 %r_V_2_3_1 to i17
  %tmp_38 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3_2 = zext i8 %window_V_3_3_load to i16
  %kernel_V_3_2_load = load i8* @kernel_V_3_2, align 1
  %rhs_V_1_3_2 = sext i8 %kernel_V_3_2_load to i16
  %r_V_2_3_2 = mul i16 %rhs_V_1_3_2, %lhs_V_1_3_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_26 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_38)
  %tmp_34_3_2_cast = sext i16 %r_V_2_3_2 to i17
  %tmp_39 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3_3 = zext i8 %window_V_3_4_load to i16
  %kernel_V_3_3_load = load i8* @kernel_V_3_3, align 1
  %rhs_V_1_3_3 = sext i8 %kernel_V_3_3_load to i16
  %r_V_2_3_3 = mul i16 %rhs_V_1_3_3, %lhs_V_1_3_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_27 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_39)
  %tmp_34_3_3_cast = sext i16 %r_V_2_3_3 to i18
  %tmp_40 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3_4 = zext i8 %window_V_3_5_load to i16
  %kernel_V_3_4_load = load i8* @kernel_V_3_4, align 1
  %rhs_V_1_3_4 = sext i8 %kernel_V_3_4_load to i16
  %r_V_2_3_4 = mul i16 %rhs_V_1_3_4, %lhs_V_1_3_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_28 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_40)
  %tmp_34_3_4_cast = sext i16 %r_V_2_3_4 to i17
  %tmp_41 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3_5 = zext i8 %window_V_3_6_loc_1_load to i16
  %kernel_V_3_5_load = load i8* @kernel_V_3_5, align 1
  %rhs_V_1_3_5 = sext i8 %kernel_V_3_5_load to i16
  %r_V_2_3_5 = mul i16 %rhs_V_1_3_5, %lhs_V_1_3_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_29 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_41)
  %tmp_34_3_5_cast = sext i16 %r_V_2_3_5 to i17
  %tmp_42 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_3_6 = zext i8 %window_V_3_6_loc_1_load_1 to i16
  %kernel_V_3_6_load = load i8* @kernel_V_3_6, align 1
  %rhs_V_1_3_6 = sext i8 %kernel_V_3_6_load to i16
  %r_V_2_3_6 = mul i16 %rhs_V_1_3_6, %lhs_V_1_3_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_3_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_30 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_42)
  %tmp_34_3_6_cast = sext i16 %r_V_2_3_6 to i18
  %tmp_43 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4 = zext i8 %window_V_4_1_load to i16
  %kernel_V_4_0_load = load i8* @kernel_V_4_0, align 4
  %rhs_V_1_4 = sext i8 %kernel_V_4_0_load to i16
  %r_V_2_4 = mul i16 %rhs_V_1_4, %lhs_V_1_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_31 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_43)
  %tmp_34_4_cast = sext i16 %r_V_2_4 to i17
  %tmp_44 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4_1 = zext i8 %window_V_4_2_load to i16
  %kernel_V_4_1_load = load i8* @kernel_V_4_1, align 1
  %rhs_V_1_4_1 = sext i8 %kernel_V_4_1_load to i16
  %r_V_2_4_1 = mul i16 %rhs_V_1_4_1, %lhs_V_1_4_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_32 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_44)
  %tmp_34_4_1_cast = sext i16 %r_V_2_4_1 to i17
  %tmp_45 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4_2 = zext i8 %window_V_4_3_load to i16
  %kernel_V_4_2_load = load i8* @kernel_V_4_2, align 2
  %rhs_V_1_4_2 = sext i8 %kernel_V_4_2_load to i16
  %r_V_2_4_2 = mul i16 %rhs_V_1_4_2, %lhs_V_1_4_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_33 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_45)
  %tmp_34_4_2_cast = sext i16 %r_V_2_4_2 to i18
  %tmp_46 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4_3 = zext i8 %window_V_4_4_load to i16
  %kernel_V_4_3_load = load i8* @kernel_V_4_3, align 1
  %rhs_V_1_4_3 = sext i8 %kernel_V_4_3_load to i16
  %r_V_2_4_3 = mul i16 %rhs_V_1_4_3, %lhs_V_1_4_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_34 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_46)
  %tmp_34_4_3_cast = sext i16 %r_V_2_4_3 to i17
  %tmp_47 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4_4 = zext i8 %window_V_4_5_load to i16
  %kernel_V_4_4_load = load i8* @kernel_V_4_4, align 4
  %rhs_V_1_4_4 = sext i8 %kernel_V_4_4_load to i16
  %r_V_2_4_4 = mul i16 %rhs_V_1_4_4, %lhs_V_1_4_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_35 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_47)
  %tmp_34_4_4_cast = sext i16 %r_V_2_4_4 to i17
  %tmp_48 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4_5 = zext i8 %window_V_4_6_loc_1_load to i16
  %kernel_V_4_5_load = load i8* @kernel_V_4_5, align 1
  %rhs_V_1_4_5 = sext i8 %kernel_V_4_5_load to i16
  %r_V_2_4_5 = mul i16 %rhs_V_1_4_5, %lhs_V_1_4_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_36 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_48)
  %tmp_34_4_5_cast = sext i16 %r_V_2_4_5 to i18
  %tmp_49 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_4_6 = zext i8 %window_V_4_6_loc_1_load_1 to i16
  %kernel_V_4_6_load = load i8* @kernel_V_4_6, align 2
  %rhs_V_1_4_6 = sext i8 %kernel_V_4_6_load to i16
  %r_V_2_4_6 = mul i16 %rhs_V_1_4_6, %lhs_V_1_4_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_4_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_37 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_49)
  %tmp_34_4_6_cast = sext i16 %r_V_2_4_6 to i17
  %tmp_50 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5 = zext i8 %window_V_5_1_load to i16
  %kernel_V_5_0_load = load i8* @kernel_V_5_0, align 1
  %rhs_V_1_5 = sext i8 %kernel_V_5_0_load to i16
  %r_V_2_5 = mul i16 %rhs_V_1_5, %lhs_V_1_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_38 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_50)
  %tmp_34_5_cast = sext i16 %r_V_2_5 to i17
  %tmp_51 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5_1 = zext i8 %window_V_5_2_load to i16
  %kernel_V_5_1_load = load i8* @kernel_V_5_1, align 1
  %rhs_V_1_5_1 = sext i8 %kernel_V_5_1_load to i16
  %r_V_2_5_1 = mul i16 %rhs_V_1_5_1, %lhs_V_1_5_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_39 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_51)
  %tmp_34_5_1_cast = sext i16 %r_V_2_5_1 to i18
  %tmp_52 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5_2 = zext i8 %window_V_5_3_load to i16
  %kernel_V_5_2_load = load i8* @kernel_V_5_2, align 1
  %rhs_V_1_5_2 = sext i8 %kernel_V_5_2_load to i16
  %r_V_2_5_2 = mul i16 %rhs_V_1_5_2, %lhs_V_1_5_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_40 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_52)
  %tmp_34_5_2_cast = sext i16 %r_V_2_5_2 to i17
  %tmp_53 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5_3 = zext i8 %window_V_5_4_load to i16
  %kernel_V_5_3_load = load i8* @kernel_V_5_3, align 1
  %rhs_V_1_5_3 = sext i8 %kernel_V_5_3_load to i16
  %r_V_2_5_3 = mul i16 %rhs_V_1_5_3, %lhs_V_1_5_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_41 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_53)
  %tmp_34_5_3_cast = sext i16 %r_V_2_5_3 to i17
  %tmp_54 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5_4 = zext i8 %window_V_5_5_load to i16
  %kernel_V_5_4_load = load i8* @kernel_V_5_4, align 1
  %rhs_V_1_5_4 = sext i8 %kernel_V_5_4_load to i16
  %r_V_2_5_4 = mul i16 %rhs_V_1_5_4, %lhs_V_1_5_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_42 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_54)
  %tmp_34_5_4_cast = sext i16 %r_V_2_5_4 to i18
  %tmp_55 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5_5 = zext i8 %window_V_5_6_loc_1_load to i16
  %kernel_V_5_5_load = load i8* @kernel_V_5_5, align 1
  %rhs_V_1_5_5 = sext i8 %kernel_V_5_5_load to i16
  %r_V_2_5_5 = mul i16 %rhs_V_1_5_5, %lhs_V_1_5_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_43 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_55)
  %tmp_34_5_5_cast = sext i16 %r_V_2_5_5 to i17
  %tmp_56 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_5_6 = zext i8 %window_V_5_6_loc_1_load_1 to i16
  %kernel_V_5_6_load = load i8* @kernel_V_5_6, align 1
  %rhs_V_1_5_6 = sext i8 %kernel_V_5_6_load to i16
  %r_V_2_5_6 = mul i16 %rhs_V_1_5_6, %lhs_V_1_5_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_5_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_44 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_56)
  %tmp_34_5_6_cast = sext i16 %r_V_2_5_6 to i17
  %tmp_57 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6 = zext i8 %window_V_6_1_load to i16
  %kernel_V_6_0_load = load i8* @kernel_V_6_0, align 2
  %rhs_V_1_6 = sext i8 %kernel_V_6_0_load to i16
  %r_V_2_6 = mul i16 %rhs_V_1_6, %lhs_V_1_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_45 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_57)
  %tmp_34_6_cast = sext i16 %r_V_2_6 to i18
  %tmp_58 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6_1 = zext i8 %window_V_6_2_load to i16
  %kernel_V_6_1_load = load i8* @kernel_V_6_1, align 1
  %rhs_V_1_6_1 = sext i8 %kernel_V_6_1_load to i16
  %r_V_2_6_1 = mul i16 %rhs_V_1_6_1, %lhs_V_1_6_1
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_1, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_46 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_58)
  %tmp_34_6_1_cast = sext i16 %r_V_2_6_1 to i17
  %tmp_59 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6_2 = zext i8 %window_V_6_3_load to i16
  %kernel_V_6_2_load = load i8* @kernel_V_6_2, align 2
  %rhs_V_1_6_2 = sext i8 %kernel_V_6_2_load to i16
  %r_V_2_6_2 = mul i16 %rhs_V_1_6_2, %lhs_V_1_6_2
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_2, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_47 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_59)
  %tmp_34_6_2_cast = sext i16 %r_V_2_6_2 to i17
  %tmp_60 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6_3 = zext i8 %window_V_6_4_load to i16
  %kernel_V_6_3_load = load i8* @kernel_V_6_3, align 1
  %rhs_V_1_6_3 = sext i8 %kernel_V_6_3_load to i16
  %r_V_2_6_3 = mul i16 %rhs_V_1_6_3, %lhs_V_1_6_3
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_3, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_48 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_60)
  %tmp_34_6_3_cast = sext i16 %r_V_2_6_3 to i17
  %tmp_61 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6_4 = zext i8 %window_V_6_5_load to i16
  %kernel_V_6_4_load = load i8* @kernel_V_6_4, align 2
  %rhs_V_1_6_4 = sext i8 %kernel_V_6_4_load to i16
  %r_V_2_6_4 = mul i16 %rhs_V_1_6_4, %lhs_V_1_6_4
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_4, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_49 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_61)
  %tmp_34_6_4_cast = sext i16 %r_V_2_6_4 to i17
  %tmp_62 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6_5 = zext i8 %in_temp_V_1_load to i16
  %kernel_V_6_5_load = load i8* @kernel_V_6_5, align 1
  %rhs_V_1_6_5 = sext i8 %kernel_V_6_5_load to i16
  %r_V_2_6_5 = mul i16 %rhs_V_1_6_5, %lhs_V_1_6_5
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_5, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_50 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_62)
  %tmp_34_6_5_cast = sext i16 %r_V_2_6_5 to i17
  %tmp_63 = call i32 (...)* @_ssdm_op_SpecRegionBegin([29 x i8]* @p_str4)
  %lhs_V_1_6_6 = zext i8 %in_temp_V_1_load_1 to i16
  %kernel_V_6_6_load = load i8* @kernel_V_6_6, align 2
  %rhs_V_1_6_6 = sext i8 %kernel_V_6_6_load to i16
  %r_V_2_6_6 = mul i16 %rhs_V_1_6_6, %lhs_V_1_6_6
  call void (...)* @_ssdm_op_SpecFUCore(i16 %r_V_2_6_6, [29 x i8]* @p_str4, [1 x i8]* @p_str, [8 x i8]* @p_str5, [1 x i8]* @p_str, i32 -1, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str)
  %empty_51 = call i32 (...)* @_ssdm_op_SpecRegionEnd([29 x i8]* @p_str4, i32 %tmp_63)
  %tmp_34_6_6_cast = sext i16 %r_V_2_6_6 to i17
  %tmp5 = add i17 %tmp_34_0_2_cast, %tmp_34_0_1_cast
  %tmp5_cast = sext i17 %tmp5 to i18
  %tmp4 = add i18 %tmp_341_cast, %tmp5_cast
  %tmp4_cast = sext i18 %tmp4 to i19
  %tmp7 = add i17 %tmp_34_0_5_cast, %tmp_34_0_4_cast
  %tmp7_cast = sext i17 %tmp7 to i18
  %tmp6 = add i18 %tmp_34_0_3_cast, %tmp7_cast
  %tmp6_cast = sext i18 %tmp6 to i19
  %tmp3 = add i19 %tmp4_cast, %tmp6_cast
  %tmp3_cast = sext i19 %tmp3 to i20
  %tmp10 = add i17 %tmp_34_1_1_cast, %tmp_34_1_cast
  %tmp10_cast = sext i17 %tmp10 to i18
  %tmp9 = add i18 %tmp_34_0_6_cast, %tmp10_cast
  %tmp9_cast = sext i18 %tmp9 to i19
  %tmp12 = add i17 %tmp_34_1_4_cast, %tmp_34_1_3_cast
  %tmp12_cast = sext i17 %tmp12 to i18
  %tmp11 = add i18 %tmp_34_1_2_cast, %tmp12_cast
  %tmp11_cast = sext i18 %tmp11 to i19
  %tmp8 = add i19 %tmp9_cast, %tmp11_cast
  %tmp8_cast = sext i19 %tmp8 to i20
  %tmp2 = add i20 %tmp3_cast, %tmp8_cast
  %tmp2_cast = sext i20 %tmp2 to i21
  %tmp16 = add i17 %tmp_34_2_cast, %tmp_34_1_6_cast
  %tmp16_cast = sext i17 %tmp16 to i18
  %tmp15 = add i18 %tmp_34_1_5_cast, %tmp16_cast
  %tmp15_cast = sext i18 %tmp15 to i19
  %tmp18 = add i17 %tmp_34_2_3_cast, %tmp_34_2_2_cast
  %tmp18_cast = sext i17 %tmp18 to i18
  %tmp17 = add i18 %tmp_34_2_1_cast, %tmp18_cast
  %tmp17_cast = sext i18 %tmp17 to i19
  %tmp14 = add i19 %tmp15_cast, %tmp17_cast
  %tmp14_cast = sext i19 %tmp14 to i20
  %tmp21 = add i17 %tmp_34_2_6_cast, %tmp_34_2_5_cast
  %tmp21_cast = sext i17 %tmp21 to i18
  %tmp20 = add i18 %tmp_34_2_4_cast, %tmp21_cast
  %tmp20_cast = sext i18 %tmp20 to i19
  %tmp23 = add i17 %tmp_34_3_2_cast, %tmp_34_3_1_cast
  %tmp23_cast = sext i17 %tmp23 to i18
  %tmp22 = add i18 %tmp_34_3_cast, %tmp23_cast
  %tmp22_cast = sext i18 %tmp22 to i19
  %tmp19 = add i19 %tmp20_cast, %tmp22_cast
  %tmp19_cast = sext i19 %tmp19 to i20
  %tmp13 = add i20 %tmp14_cast, %tmp19_cast
  %tmp13_cast = sext i20 %tmp13 to i21
  %tmp1 = add i21 %tmp2_cast, %tmp13_cast
  %tmp1_cast = sext i21 %tmp1 to i22
  %tmp28 = add i17 %tmp_34_3_5_cast, %tmp_34_3_4_cast
  %tmp28_cast = sext i17 %tmp28 to i18
  %tmp27 = add i18 %tmp_34_3_3_cast, %tmp28_cast
  %tmp27_cast = sext i18 %tmp27 to i19
  %tmp30 = add i17 %tmp_34_4_1_cast, %tmp_34_4_cast
  %tmp30_cast = sext i17 %tmp30 to i18
  %tmp29 = add i18 %tmp_34_3_6_cast, %tmp30_cast
  %tmp29_cast = sext i18 %tmp29 to i19
  %tmp26 = add i19 %tmp27_cast, %tmp29_cast
  %tmp26_cast = sext i19 %tmp26 to i20
  %tmp33 = add i17 %tmp_34_4_4_cast, %tmp_34_4_3_cast
  %tmp33_cast = sext i17 %tmp33 to i18
  %tmp32 = add i18 %tmp_34_4_2_cast, %tmp33_cast
  %tmp32_cast = sext i18 %tmp32 to i19
  %tmp35 = add i17 %tmp_34_5_cast, %tmp_34_4_6_cast
  %tmp35_cast = sext i17 %tmp35 to i18
  %tmp34 = add i18 %tmp_34_4_5_cast, %tmp35_cast
  %tmp34_cast = sext i18 %tmp34 to i19
  %tmp31 = add i19 %tmp32_cast, %tmp34_cast
  %tmp31_cast = sext i19 %tmp31 to i20
  %tmp25 = add i20 %tmp26_cast, %tmp31_cast
  %tmp25_cast = sext i20 %tmp25 to i21
  %tmp39 = add i17 %tmp_34_5_3_cast, %tmp_34_5_2_cast
  %tmp39_cast = sext i17 %tmp39 to i18
  %tmp38 = add i18 %tmp_34_5_1_cast, %tmp39_cast
  %tmp38_cast = sext i18 %tmp38 to i19
  %tmp41 = add i17 %tmp_34_5_6_cast, %tmp_34_5_5_cast
  %tmp41_cast = sext i17 %tmp41 to i18
  %tmp40 = add i18 %tmp_34_5_4_cast, %tmp41_cast
  %tmp40_cast = sext i18 %tmp40 to i19
  %tmp37 = add i19 %tmp38_cast, %tmp40_cast
  %tmp37_cast = sext i19 %tmp37 to i20
  %tmp44 = add i17 %tmp_34_6_2_cast, %tmp_34_6_1_cast
  %tmp44_cast = sext i17 %tmp44 to i18
  %tmp43 = add i18 %tmp_34_6_cast, %tmp44_cast
  %tmp43_cast = sext i18 %tmp43 to i19
  %tmp46 = add i17 %tmp_34_6_4_cast, %tmp_34_6_3_cast
  %tmp46_cast = sext i17 %tmp46 to i18
  %tmp47 = add i17 %tmp_34_6_6_cast, %tmp_34_6_5_cast
  %tmp47_cast = sext i17 %tmp47 to i18
  %tmp45 = add i18 %tmp46_cast, %tmp47_cast
  %tmp45_cast = sext i18 %tmp45 to i19
  %tmp42 = add i19 %tmp43_cast, %tmp45_cast
  %tmp42_cast = sext i19 %tmp42 to i20
  %tmp36 = add i20 %tmp37_cast, %tmp42_cast
  %tmp36_cast = sext i20 %tmp36 to i21
  %tmp24 = add i21 %tmp25_cast, %tmp36_cast
  %tmp24_cast = sext i21 %tmp24 to i22
  %out_temp_V_6_6 = add i22 %tmp1_cast, %tmp24_cast
  %tmp_24_tr = sext i22 %out_temp_V_6_6 to i23
  %tmp_25_tr = sext i8 %kernel_sum_V_load to i23
  %r_V = sdiv i23 %tmp_24_tr, %tmp_25_tr
  %tmp_66 = trunc i23 %r_V to i8
  %r_V_2 = add i8 %kernel_off_V_load, %tmp_66
  call void @_ssdm_op_Write.axis.volatile.i8P(i8* %out_img_V, i8 %r_V_2)
  br label %._crit_edge66

._crit_edge66:                                    ; preds = %pixel_weighted_average.exit, %.loopexit._crit_edge
  %tmp_32 = add i19 %convolution_filter_ap_int_ap_6, 1
  %empty_52 = call i32 (...)* @_ssdm_op_SpecRegionEnd([9 x i8]* @p_str10, i32 %tmp_1)
  %col_1 = add i10 %col_mid2, 1
  br label %0

.reset:                                           ; preds = %0
  call void (...)* @_ssdm_op_SpecLoopName([18 x i8]* @Loop_row_Loop_col_str)
  %empty_53 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 310569, i64 310569, i64 310569)
  %tmp_2 = add i19 %convolution_mulfilter_ap_int_ap, 643
  %exitcond = icmp eq i10 %col, -381
  %convolution_filter_ap_int_ap_6 = select i1 %exitcond, i19 %tmp_2, i19 %convolution_filter_ap_int_ap_3
  %col_mid2 = select i1 %exitcond, i10 0, i10 %col
  %row_s = add i9 %row, 1
  %tmp_mid1 = icmp ult i9 %row_s, -32
  %tmp = icmp ult i9 %row, -32
  %tmp_mid2 = select i1 %exitcond, i1 %tmp_mid1, i1 %tmp
  %tmp_2_mid1 = icmp ugt i9 %row_s, 2
  %tmp_9 = icmp ugt i9 %row, 2
  %tmp_2_mid2 = select i1 %exitcond, i1 %tmp_2_mid1, i1 %tmp_9
  %convolution_filter_ap_int_ap_7 = select i1 %exitcond, i19 %tmp_2, i19 %convolution_mulfilter_ap_int_ap
  %row_mid2 = select i1 %exitcond, i9 %row_s, i9 %row
  call void (...)* @_ssdm_op_SpecLoopName([9 x i8]* @p_str10) nounwind
  %tmp_1 = call i32 (...)* @_ssdm_op_SpecRegionBegin([9 x i8]* @p_str10)
  call void (...)* @_ssdm_op_SpecPipeline(i32 1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %tmp_4 = icmp ult i19 %convolution_filter_ap_int_ap_6, 49
  br i1 %tmp_4, label %._crit_edge63, label %1

; <label>:7                                       ; preds = %0
  ret void

branch0:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch13 [
    i3 0, label %branch7
    i3 1, label %branch8
    i3 2, label %branch9
    i3 3, label %branch10
    i3 -4, label %branch11
    i3 -3, label %branch12
  ]

branch084:                                        ; preds = %branch13, %branch12, %branch11, %branch10, %branch9, %branch8, %branch7
  br label %._crit_edge6376

branch1:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch20 [
    i3 0, label %branch14
    i3 1, label %branch15
    i3 2, label %branch16
    i3 3, label %branch17
    i3 -4, label %branch18
    i3 -3, label %branch19
  ]

branch193:                                        ; preds = %branch20, %branch19, %branch18, %branch17, %branch16, %branch15, %branch14
  br label %._crit_edge6376

branch2:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch27 [
    i3 0, label %branch21
    i3 1, label %branch22
    i3 2, label %branch23
    i3 3, label %branch24
    i3 -4, label %branch25
    i3 -3, label %branch26
  ]

branch2102:                                       ; preds = %branch27, %branch26, %branch25, %branch24, %branch23, %branch22, %branch21
  br label %._crit_edge6376

branch3:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch34 [
    i3 0, label %branch28
    i3 1, label %branch29
    i3 2, label %branch30
    i3 3, label %branch31
    i3 -4, label %branch32
    i3 -3, label %branch33
  ]

branch3111:                                       ; preds = %branch34, %branch33, %branch32, %branch31, %branch30, %branch29, %branch28
  br label %._crit_edge6376

branch4:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch41 [
    i3 0, label %branch35
    i3 1, label %branch36
    i3 2, label %branch37
    i3 3, label %branch38
    i3 -4, label %branch39
    i3 -3, label %branch40
  ]

branch4120:                                       ; preds = %branch41, %branch40, %branch39, %branch38, %branch37, %branch36, %branch35
  br label %._crit_edge6376

branch5:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch48 [
    i3 0, label %branch42
    i3 1, label %branch43
    i3 2, label %branch44
    i3 3, label %branch45
    i3 -4, label %branch46
    i3 -3, label %branch47
  ]

branch5129:                                       ; preds = %branch48, %branch47, %branch46, %branch45, %branch44, %branch43, %branch42
  br label %._crit_edge6376

branch6:                                          ; preds = %._crit_edge63
  switch i3 %tmp_65, label %branch55 [
    i3 0, label %branch49
    i3 1, label %branch50
    i3 2, label %branch51
    i3 3, label %branch52
    i3 -4, label %branch53
    i3 -3, label %branch54
  ]

branch6138:                                       ; preds = %branch55, %branch54, %branch53, %branch52, %branch51, %branch50, %branch49
  br label %._crit_edge6376

branch7:                                          ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_0, align 1
  br label %branch084

branch8:                                          ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_1, align 1
  br label %branch084

branch9:                                          ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_2, align 1
  br label %branch084

branch10:                                         ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_3, align 1
  br label %branch084

branch11:                                         ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_4, align 1
  br label %branch084

branch12:                                         ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_5, align 1
  br label %branch084

branch13:                                         ; preds = %branch0
  store i8 %kernel_config_V_load, i8* @kernel_V_0_6, align 1
  br label %branch084

branch14:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_0, align 1
  br label %branch193

branch15:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_1, align 1
  br label %branch193

branch16:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_2, align 1
  br label %branch193

branch17:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_3, align 1
  br label %branch193

branch18:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_4, align 1
  br label %branch193

branch19:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_5, align 1
  br label %branch193

branch20:                                         ; preds = %branch1
  store i8 %kernel_config_V_load, i8* @kernel_V_1_6, align 1
  br label %branch193

branch21:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_0, align 1
  br label %branch2102

branch22:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_1, align 1
  br label %branch2102

branch23:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_2, align 1
  br label %branch2102

branch24:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_3, align 1
  br label %branch2102

branch25:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_4, align 1
  br label %branch2102

branch26:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_5, align 1
  br label %branch2102

branch27:                                         ; preds = %branch2
  store i8 %kernel_config_V_load, i8* @kernel_V_2_6, align 1
  br label %branch2102

branch28:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_0, align 1
  br label %branch3111

branch29:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_1, align 1
  br label %branch3111

branch30:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_2, align 1
  br label %branch3111

branch31:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_3, align 1
  br label %branch3111

branch32:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_4, align 1
  br label %branch3111

branch33:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_5, align 1
  br label %branch3111

branch34:                                         ; preds = %branch3
  store i8 %kernel_config_V_load, i8* @kernel_V_3_6, align 1
  br label %branch3111

branch35:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_0, align 1
  br label %branch4120

branch36:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_1, align 1
  br label %branch4120

branch37:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_2, align 1
  br label %branch4120

branch38:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_3, align 1
  br label %branch4120

branch39:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_4, align 1
  br label %branch4120

branch40:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_5, align 1
  br label %branch4120

branch41:                                         ; preds = %branch4
  store i8 %kernel_config_V_load, i8* @kernel_V_4_6, align 1
  br label %branch4120

branch42:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_0, align 1
  br label %branch5129

branch43:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_1, align 1
  br label %branch5129

branch44:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_2, align 1
  br label %branch5129

branch45:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_3, align 1
  br label %branch5129

branch46:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_4, align 1
  br label %branch5129

branch47:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_5, align 1
  br label %branch5129

branch48:                                         ; preds = %branch5
  store i8 %kernel_config_V_load, i8* @kernel_V_5_6, align 1
  br label %branch5129

branch49:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_0, align 1
  br label %branch6138

branch50:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_1, align 1
  br label %branch6138

branch51:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_2, align 1
  br label %branch6138

branch52:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_3, align 1
  br label %branch6138

branch53:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_4, align 1
  br label %branch6138

branch54:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_5, align 1
  br label %branch6138

branch55:                                         ; preds = %branch6
  store i8 %kernel_config_V_load, i8* @kernel_V_6_6, align 1
  br label %branch6138
}

define weak void @_ssdm_op_Write.axis.volatile.i8P(i8*, i8) {
entry:
  store i8 %1, i8* %0
  ret void
}

define weak void @_ssdm_op_SpecTopModule(...) {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecRegionEnd(...) {
entry:
  ret i32 0
}

define weak i32 @_ssdm_op_SpecRegionBegin(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecPipeline(...) nounwind {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecMemCore(...) {
entry:
  ret i32 0
}

define weak i32 @_ssdm_op_SpecLoopTripCount(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecLoopName(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecInterface(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecFUCore(...) {
entry:
  ret void
}

define weak void @_ssdm_op_SpecBitsMap(...) {
entry:
  ret void
}

define weak i8 @_ssdm_op_Read.axis.volatile.i8P(i8*) {
entry:
  %empty = load i8* %0
  ret i8 %empty
}

declare i8 @_ssdm_op_PartSelect.i8.i23.i32.i32(i23, i32, i32) nounwind readnone

declare i3 @_ssdm_op_PartSelect.i3.i32.i32.i32(i32, i32, i32) nounwind readnone

declare void @_GLOBAL__I_a() nounwind

!hls.encrypted.func = !{}
!llvm.map.gv = !{!0}

!0 = metadata !{metadata !1, [1 x i32]* @llvm_global_ctors_0}
!1 = metadata !{metadata !2}
!2 = metadata !{i32 0, i32 31, metadata !3}
!3 = metadata !{metadata !4}
!4 = metadata !{metadata !"llvm.global_ctors.0", metadata !5, metadata !"", i32 0, i32 31}
!5 = metadata !{metadata !6}
!6 = metadata !{i32 0, i32 0, i32 1}
!7 = metadata !{metadata !8}
!8 = metadata !{i32 0, i32 7, metadata !9}
!9 = metadata !{metadata !10}
!10 = metadata !{metadata !"kernel_config.V", metadata !11, metadata !"int8", i32 0, i32 7}
!11 = metadata !{metadata !12}
!12 = metadata !{i32 0, i32 50, i32 1}
!13 = metadata !{metadata !14}
!14 = metadata !{i32 0, i32 7, metadata !15}
!15 = metadata !{metadata !16}
!16 = metadata !{metadata !"in_img.V", metadata !17, metadata !"uint8", i32 0, i32 7}
!17 = metadata !{metadata !18}
!18 = metadata !{i32 0, i32 307199, i32 1}
!19 = metadata !{metadata !20}
!20 = metadata !{i32 0, i32 7, metadata !21}
!21 = metadata !{metadata !22}
!22 = metadata !{metadata !"out_img.V", metadata !17, metadata !"uint8", i32 0, i32 7}
